    A Rehabilitation of Message-Passing Currency
    by Frank Pfenning
    
    >> All right, take some seats, everybody. And get, you know, make sure you use all the empty seats so everybody can sit. Cool. This is exciting. Frank Pfenning's work I've known for a long time, or at least three years, because I went to this really awesome place called the Oregon Programming Summer School. I actually recommend it, it's actually more affordable than most conferences, though more expensive than Papers We Love Conf, but Frank gave lectures in both summers went there. I learned more from Frank's teaching -- I'm in Frank's class right now actually I'm learning so much, but Frank is amazing. He's done really great work, showcasing so many different forms of ideas in logic and type theory and programming languages. His lecture notes are available online on his website for years and years of classes. Mobile logic, regular programming language theory, so many things. Download those notes, because they're like the best thing ever. I'm actually putting a book together for myself in my reader so Frank is amazing and we've been trying to get Frank here for the last couple of years and we talked about it for PWL Conf 1, and we're really happy to have him here today, so thank you, Frank.
    [applause]
    
    >> Yeah, I'd like to thank Zeeshan and the organizers to give me a chance to talk about the thing that I'm really passionate about, which is programming. So I really want to talk about message passing concurrency and to some respect I feel a rehabilitation is in order and that's why I've called the talk this way but you'll see. It's written a paper I love. Which is types for dyadic interaction for 1993 and it's what we call a classic, by the definition of classic is that everybody cites a paper, nobody reads it. I must admit to that same mistake for a while, but eventually I did read it and so I can talk to you about it today. So just yesterday I finished.
    [laughter]
    
    OK, so it appeared in Concur1993, but we're still elaborating and thinking about the work that he worked on there. With some in your developments. OK. So that's a photo of Kohei. Very unfortunately he died very young in 2012. I had the good fortune to get to know him a little bit. He was a nice guy to talk about and so it's very poignant to talk about his paper here at this conference. So the activity of programming. What is programming all about? So I'll give you this little program fragment. There's sort (A) x = A of 0. Anybody want to take a shot at it? You get the minimum value of A, right? Now there's other things that you have think to think about as you look at this bit of code. What else is there to be said about this program?
    So it computes the minimum value of A and puts it into X if we do the right thing, but what else does it do? There must be at least one element in A, OK, otherwise this reference will be out of bounds. What else?
    Yeah, it modifies in place, which is what you would expect, because otherwise this work would be completely meaning less, right, if it doesn't modify it. Here's another program, if you're a functional programmer like me, you'd like to look at this piece of code, OK? So what do we infer about that, we infer that it returns a value of that rather than mutating it into place. Or at least we think it might not mutate in place. So it depends on whether you're programming in L or Haskell or whether there's a monad involved or whatever. Also, you should not be able to take the head of that, OK? And so why am I showing you this? Because I want to get home to the fact that every programmer all the time, reasons operationally, for example, we do first this sort and then we do this assignment or we do this sorting and then we take this logically what. I just say sort and it sorts the array either in place or returns it. And so you need to reason about what the piece of code accomplishes all the time, without even knowing how all that's done, OK?
    First is how programs execute. Obviously that's the operational reasoning. And secondly, what they achieve, and that's because you need to know that while this is sorted afterwards or this returns a sorted list, but then also, which reasoning principles connect the operational and logical meaning of a program. OK? So when you reason about this thing, you say, well, this is going to leave A unchanged, because while it may be a point of purely functional language, that actually has to be true about the programming language for you to make this deduction and a lot of bugs happen because the programming language that you work in doesn't give you an effective way to connect the operational and logic of reasoning about your code.
    OK. So why is functional programming so effective? OK. OK, so the obvious thing is that functions are a fundamental abstraction and universal. So I was just teaching in the course that Zeeshan is in, and you know, every programming language that I of has a language of function. And then the way I think about the operational and the logic of reasoning fitting together is in this kind of a triangle. Ju down here we have the computation. And then we have the logic where you can reason about what the program accomplishes and types are connecting these two along these two axes here. So we can fill this in in many different ways, but we know a lot, we know ultimately computation here is usually reduced to beta reduction, which is a very fundamental notion of substitution and computation and then for a logic we have intuitionistic logic. And then we can extract from that even if we don't formalize fully the reasoning a type system that is kind of an image of the logic of reasoning into the programming language that has, for example, function type and product and sums and maybe type variables and so on.
    So because we can fill in these -- the parts of the diagram, if you know how they connect, we actually know that we're working within a good paradigm and I think this is one of the big reasons why functional programming, at least for me personally, having written many programs in different types of languages, is effective. And this fits into type theory by looking at both the computation, about the logic of reasoning about the programs and the types that connect those two.
    But a word about concurrency, OK?
    So the first thing we saw in the previous talk a lot of talk about shared memory and I do wonder if shared memory is really a fundamental abstraction, because right now, shared memory is kind of a very difficult thing, we're in an interesting period where the guarantees that the hardware gives you is much less than you'd like in some sense and a lot of papers have been written about that.
    And what about the triangle? What do we know about that? . Well, the computation is read-write, shared memory so that's fairly obvious, there are also some logics about concurrent programs using shared memory. Something like concurrent separation logic, but there isn't a good type level abstraction of that, and I think that's really an impediment to write shared memory programs and write them well. OK.
    But opened, we know since Milner, that processes and internals are a fundamental abstraction and so that's what we should be looking at. So if you look at triangle, at first the picture doesn't look much better. First in computation we have made process, because Milner introduced the pi-calculus and that cap tours the passing messages. But what about the logic part and the types part? Without that the pi-calculus is a specification language but it's not really a programming language. I do write a lot of programs, and these kind of things are important.
    But now we're beginning to have an answer, and the paper I love gave an answer down in the lower left-hand corner, namely the right notion of types for communicating processes is what Honda called session types.
    OK, so that's a very important element. What's still open is what kind of logic should be used, at that point in '93, and that kind of piqued my interest and together with a coauthor, we made a proposal here and we think the right thing to bridge these things is linear logic and we had a paper in Concur in 2010. So I'm not actually going to separate out these contribution in my talk but I'm going to present the ideas mostly the ones by Honda, but with some influence of what I did later on.
    But now if we look at this picture, we have a lot of things built in and I think it's time to actually build effective programming language constructs now that we know what the right abstractions are to write concurrent programs. And I think it's much easier than writing shared memory programs and I think more people should care about message passing than those who care about shared memory concurrency. So right now in the research community the balance is in the other direction and I think we need to rehabilitate message-passing concurrency and my long-term goal and I'm definitely not there, is to actually build a concurrent type theory, but we've made some progress in that, but there's still some open questions. So there's hope. You saw them in the previous talk. We can give tools even for shared memory concurrency that make it easy to write concurrent programs or avoid certain kinds of bugs. From the language point of view one language is Go which we use at Carnegie Mellon University in some of our systems courses. So why is Go a. It has two abstractions that are really important, one is an abstraction called goroutine. It's a fundamental abstraction of something that executes concurrently with something else.
    And they have channels, as a fundamental abstraction and would you have channel tao, and we have in this language not coded somehow but as a primitives, the notion of a Goroutine and the notion of a channel. But even with that, the connection to the logic is missing, so these were designed basically only from the programming and typing point of view but not so much from the logical point of view and to be effective from programming, you need to understand that, as well, because as I showed you at the very beginning, every programmer always reasons about their code, always, at every step of the way.
    And these types are not expressive enough as it turns out.
    OK. So thos actually from the effective Go website, which says that do not communicate by sharing memory, instead share memory by communicating. And in my own coding I've found this many times.
    So as an example, we're going to write some code, I was toying with the idea of live-coding for a while, but then I decides we're going to write some code on the slide like line by line and what we're going to put in is a store, either a stack or a queue, something very simple.
    So the overall picture is something like this. You have a provider over here and you have a client over here and you have a channel, I'm going to prefix channel in from the dollar to distinguish them from other kinds of variables and Honda called this a dyadic channel, because it has two endpoints. For most of the talks all of the channels we're considering have just two endpoints, OK? .
    So that's a picture you should have in mind. OK, so now to interface with a store, we want to implement like the following protocol, OK? : So the client sends to the provider: Some kind of a label that says I want to insert. Then it sends the element x, and then we recurse, then the provider responds. The provider says oh, there's nothing in the store, sends the label none and then closes the connection. OK, that's not forced, but it turns out to be often convenient. Or the provider says oh, yeah, there aren't something in the store, send some element e back and then we recurse. We'd like them to send it back to us in some order, maybe a stack, maybe a queue, we don't care, we just want to make sure we get all the elements back, without duplication and without anything dropped.
    This protocol should be expressed by a type. This is the central idea of the paper and the central idea of this talk, OK? You have a communication protocol bought a provider and a client or between two processes and the communication protocol, the behavior that's being prescribed should be expressed by a type. If you do that, then you can rule out many, many programming errors by seeing that, well, your code doesn't have this type, it doesn't follow this protocol, and also it turns out what we later discovered, you get a close connection to logic. OK, so some terminology. If you're the provider, then if the client can choose between an insert and a delete label here, that's a client choice, we call that an external choice. Now, when the client wants to delete, now, the provider can choose to send either none or some. So we call this the provider's choice or the internal choice. So there's two forms of choice. Both of them are disjunction in some sense. Because but who chooses is different. So these become opposite constructs. OK, so now actually we come to the coding part. So writing a simple, we're beginning by writing a simple client and syntax, I've chosen concurrency naught which is a language which I implemented. It's variant of C, extended with concurrency construct inspired by Kohei's work
    So the next line is interesting. I haven't explained to you what the type stack is, but it is the type of a channel. And the channel here is s, s stands for stack and some kind of function here, we give it no parameters and it gives us back a channel. OK, so now for the rest of this code, s will refer to a channel. So from the picture, empty will be running a process that provides along this channel and the main function here is the client of this channel, OK? So now we want to insert some things and push some things into the stack. So we have a little 4 loop. I + +. I teach introductory programming, I've written this thing maybe 50 gazillion times, OK?
    [laughter]
    
    OK, now the next piece of code is something you don't write very often. Along the channel s we send a label ins. It's not a value but it's actually a label. So because the type of stack will be an external choice, we actually get to send a label and then we went to insert. And then we send the channel s integer i, and then we close the loop. So that should insert from elements from 0 to n-1 into the queue. Now we want to print it. Now there's the difference here, that is function. Unlike this, it doesn't return a channel. It just executes. It has type void something, so it doesn't return anything, but it will print the stack for us. Now, as we do this, we pass the channel to this function, which means that we actually no longer have it. Because the channel is two inputs. If we also pass it into the function and we also reference it, there will be two endpoints, so we can't do that. So that's gone. And then we return a function.
    At the beginning, after this line, the picture looks like this. So there is some process executing empty, providing along a channel s which has type stack, and then the main function executing here is the client. And then down here we don't actually know what this process is executing because we send a bunch of messages and it has some internal state because it wants to keep track of the stack, so we don't know what it's executing but we know it's providing s and we're still the client. And then here we are passing s to print stack, it's a process it's already executing and this channel s now goes to this function and the end of that here the process is gone, so print stack someone has to close that channel and terminate that and main is the only thing that you return.
    By the way all the credentialing today executes and has the right amount of concurrency in it when you actually run it. OK.
    So now, the interesting thing is to actually now write a provider that matches that, OK? So let's write this piece of code. So a stack -- so we have a function element, OK, and this function holds an element x of the stack which is given as an argument here. It also holds a reference to a remaining stack and it provides a stack. So here is the first thing that's different from a function. So a function just returns a value. This returns a channel of type stack but we also want to give it a name so we can reference it in our code, OK? All right, now, remember that the stack is an external choice, we provided -- our client is going to tell us, I want to insert something or I want to delete something. So the switch construct here does that, OK? So if you receive an insert request that's one case laid on we'll see the delete request, then the next thing you receive is actually the integer. Remember the protocol says send insert and then send the element and then we somehow want to recurse. The way I want to implement this stack is have one Goroutine or one process for each element. So I'm starting a new element here and that gives me a new channel r, and this process here will hold x and also the element in channel t which I already had, and then I recurse, providing along s with an element portion now we hold the element y and the channel r that we just created is our tail. So we have insert in the middle. I'll show a picture in a little bit. All right, and the other possibilities that we're supposed to delete. OK, so in that case because we hold an element x, we're sending back the message, yes, we have something, then we send x along s, and then at this point because R. because we're supposed to delete it from the queue, we actually terminate and say further requests should go to the tail of this stack and so we say from now on s is implemented from t. Here's what it looks like. At the beginning here we're in element process, we have a pointer or a channel to the rest of the stack, and to the client we expose that s which is the stack, and we're executing the element x and t are some arguments.
    OK, so when we're at this point we're supposed to insert and so our client can will send us insert and the element y, we're still running this. And at this point here, OK, what we did is, we started a new process element x by giving it t which we originally had, so giving it to this new process, we're giving it x so it will hold x, now we recurse, holding the element y and that should be an r, OK, the type checker would have caught that, OK? Sorry about that, this should be the r and you can see it's the r from the thing over here, so yup, I need to figure out how to get these pictures to be type checked.
    [laughter]
    
    That code over there is actually fine. OK. So now -- so I wanted to go through the case for delete, so for delete, we get to this point here, the client sends a delete message to our process we're holding x and t, so we're sending back and then we send back x in sequence, so some and then x and now we're in this situation that we have responded with this. Now this element is supposed to be away because we're popping it from the stack, so we want to get to the situation where we say from now on the client, don't talk to us, talk to the tail which starts with here. And we do this by this operation called forwarding or by saying from now on, s is implemented by t, and the type is stack should be good.
    So this is how we program in this kind of a language. And the important part to realize is that as we go through the code, the types of the channels changes all the time. So for example, right here when we do the switch, before the switch, s is type stack. After the switch, it cannot have type stack, because we no longer receive inserted delete, but we now receive the element. Which is unusual for a type system, but it's perfectly meaningful. It just means that the type checker has to be a little bit different than the type checker that we're used to, OK? OK, so this has causes some headaches, forwarding, because it is not part of the pi-calculus, so you either have to eliminate it or you have to say, OK, we'll bite the bullet and put it in there. Putting it in there is a much nicer way to do this.
    Now we need to write the empty stack. A little bit programming. Like I said at the beginning, I really care about programming, OK, so we have the empty stack and we offer some channel s, and we switch s and it could be an insert or it could be a delete. If it's an insert, then the next thing we see is an element, OK? Now what do we do at this point, OK? You probably know what's coming next. OK, we have to start a new empty stack, and then we call the element process here, we're giving it x the element that we received and we're getting into the new empty stack that's the tail and that's what implements s, OK? So we go from being an empty stack, now executing element in this approximate we're holding the element x, but the tail is still empty, OK, then we get a delete and then we say OK, we hold nothing, and then we're supposed to terminate the computation or this process, so we close a channel, and closing a channel that we're providing is the same thing as terminating, but it also sends a message to our client, saying, hey, we're done and then we just close some parentheses. So the picture initially looks like this and then we get the insert and the x message and so at this point we have started a new empty process here, and we're holding it here, so this time I put the right thing here, OK?
    And s is still a stack and then we call element which I showed you on the previous slide, OK?
    And last animation here, under s is the stack, beginning, if we see the delete message, OK, so we're now at this point, we send a none message and then we terminate. And that's how you code in this kind of language. And you can do this functionally and empirically. It's actually very natural match, because an object is like a process, and the original conception of object-oriented programming, there was supposed to be communicating processes with messages being sent back and forth, which is exactly what this allows you to do.
    So processes provide one channel and are clients to other channels. Could be multiple ones. Now when you're spawning a process, returns a fresh channel. It has two endpoints. So the new process provides along this channel, and the spawning process is a client. And because we spawn at a different type, we know that the provider and the client agree on the type. As we communicate the type will evolve, OK? Process can terminate by forwarding, OK? If I say OK I'm done, just talk to this guy over there now, or we can terminate potentially by just saying OK, we're closing the channel. And communication is bidirectional. So I can respond to messages, so it's not like the provider always receives the messages or always sends the messages.
    And what you send is receive labels or integers. In a more general framework, we also send along channels and that changes according to pi-calculus and gives you mobility and there's actually programs that do that.
    Now, the typing channels. The provider and the client must execute complementary actions. If a client sends, then the client will receive and so on and conversely. So we have external choice, so the provider branches on a label, the client sends one. We have internal choice, we have termination, provider terminates, client waits for it and we have basic data, sending and receiving atomic values, which complementary actions. So abstractly, this is what the type system looks like.
    So this here is called the external choice. Between all the labels in this label set and so the provider means it has to branch on which k in this label set L it receives among all of these possible labels. Once it receives a label k, then it continues with the branch case of k, now, this is an internal choice. You have to send one of these labels. You have this weird type constructor here which is like a function, but you don't receive a value, you receive a channel. This constructor here which is sort of like a product, you send a channel c of Type A and then you continues as B. Type I, you terminate and there's no continuation because nothing to be done. And universal quantity fire receiving values around basic values like integers. OK? So how would we describe a stack type now? Stack with elements of Type A. So it's probably morphic in A here. It's an external choice where the client says either insert or delete. It next sends an element of Type A, a channel of Type A, really and then it behaviors again like a stack. Or it sends a delete. And you have to either by sending a none and then determining an element of Type A and then you behave like a stack, OK? Now, a side effect of this because these all what's called linear types, the stack will also have to preserve all the elements. It can't drop all the elements on the floor, it can't duplicate any elements if it satisfies this type. But that's not really the main point of the session types at all. The main point is really to describe the mode of communication and then checking that the program will satisfy the protocol.
    Now when you get to the top of the pyramid and you're trying to figure out what is the logical meaning of that, you realize that these types are exactly the propositions of linear logic except for the so-called bang operator, exponential operator, that we don't have yet, but we'll come to that later. So it's really an instance of the Curry-Howard correspondence. The programs correspond to process expressions, or I should have said proofs correspond to process expressions and communication corresponds to a process called ...
    So what are the judgments just to give you brief introduction of what they look like, so we have what's called a sequent, we label these with variables but these a really channels in this case. So when you actually run the process P, when you write a functional program and all of these variables have been substituted for, when you run a process these variables will have been substituted for by various channels so they still will be substituted in types.
    So then a configuration as your program runs, many processes execute, they execute in parallel. So configuration looks like a bunch of these. Configuration of omega uses all the channels in gamma and provides all the changes in gamma Prime. So if you plug together two processes they communicate internally and you won't see these channels either here or here.
    All right, what are the theoretical properties? So without recursive types and processes you get these properties: So you get session fidelity, it will be deadlock-free, so it can't actually deadlock, and without recursion, it will also terminate, but of course in practice, you need recursion, like the process stack, the type stack was recursive, and then if you do that, you still have these two properties. So every program that's well typed will satisfy the protocol, and also, it will be deadlock free. So here's a formal statement of that. It says if you have a well typed configuration with a certain interface and the configuration types a step to omega' and then deadlock freedom means that if you have a well typed configuration, either it's poised and poised means that it tries to communicate either along gamma or gamma', OK, and termination means that well, OK, any sequence of deductions will terminate. So here's a definition of poised. Here's a side remark on the mode of communication. Both synchronous and asynchronous communication can be supported here. In asynchronous, you can send a message, you can continue with the main thread of computation, but you cannot reorder the messages, because it would violate session fidelity, right, so if you have a boolean and then you send and integer, if the messages can't arrive from the opposite order there's no way you can preserve type correctness of that communication. And then if you have synchronous communication, then you can also actual code messages and the way you can code a message is by a process that all it does is it delivers a message and then it forwards. So messages can be coded. So unlike the un
    Asynchronous seems to be the right default because it's closer to reasonable implementation, and also it generalizes to channels. If you have one provider and multiple clients they all would have to see the message the same time, it seems like a very strange operation.
    OK, so in concurrency 0, we have some weird syntax force all of this. I guess I can show it to you. Now, keep in mind, this is inspired by C and so on, so you have to forebear me Hoar and OK. So we have something choice which is like a struck, so it names something like a stack_req, and then inside these angle brackets is the type response. So it means that if the client requests insert, we now have to expect an integer and then we recurse. If it sends delete, we have to respond with a choice that's given by stack response which is down here, we either have to send a label none and then we terminate. If we send and integer, then we recurse back to here. And then the type stack that I've use in the code is the only one we need to refer to. So all of this, yeah, so there's a weird thing in C that the label is here, and so you have to jump around in this type, but OK, we kind of inherited that. OK, tracing the type-checker. I think I have time to give you just a little bit of an idea how the type-checker has to operate. It's not super-tricky, OK? So for example in this point in the code, what's the type of the channel S and the type of a channel T? So we have seen the label insert, so we have gone through that part of the protocol. So the next thing should be this. So at this point, the channel s has a type, receive an integer and then behave again like a stack, OK? And then we recurse s back to a type of a stack and then once we respond this new process element and we give it t, t disappears from our context, because we have passed it on to this context, if we pass it along, we can no longer refer to it, OK? But we have gained r, because that's the r that's now in our context, because this element process will provide that for you us, okay, and so now the types are all lined up so we can recall element recursively.
    We send some and then we proceed this this type, we have to send an integer and then we have to behave like a stack. T over here doesn't change its stack all the way, then we send and x and it doesn't change, but then at this point we have proceeded to be a again a stack and then we do the forwarding and that actually works out because s and t have the same type. at this point, s and t do have the same type, so we can terminate, get out of the way and close the parentheses. So that's what the type-checker has to do, it's not too hard, it's not too difficult to implement, actually. If you make a mistake, say for example you forget to read the element y here, you'll get an error and the compiler will tell you something. I actually worked very hard on this error message. If you get around to playing with this, OK? I would say that at least 75% of my work on this code was to get these error messages to be slightly meaningful, OK?
    [laughter]
    
    I'll skip over this because I don't think it adds more. Now I have 10 minutes and let me talk to you about the problem of sharing. That's the last paper and it fixes some expression issues that we have so far. So let's say I'm doing this red now and I use this hashtag here saying this is a shared channel. So you have a channel that has one provider as before, but it has two clients. So that's something you might want to set up in concurrent programming. So if both the clients can freely interact along this channel, session fidelity will be violated.
    Once this insert is being processed in store, it proceeds in the process of the store, that's the next thing that happens after you see insert, you read along this channel an element, but now this thing is not an element. So we cannot just have something like this, OK? So what do we have to do?
    What we have to do is generalize our logic, but in ways that are completely -- have been done before, we just used it, OK?
    So this is all that we had before, but you remember we said we don't have the band connective, the exponential connective. Now, we don't take the exponential directly, but we do compose in two things. So we have a down arrow in the share type S, and the meaning of up A is that this is a shared channel, S, or a process of this type is going to be shared, and what the up arrow means, you accept a client, OK? Once you accept the client, the client has exclusive access to you, and you proceed with a linear Type A until you hit a downshift, which means that now you have to detach on the client and you become again shared of type S, OK? So the image that you should have from the previous slide -- not this one, but this one -- is that we avoid this problem because we have to send at this point the client has to send an acquire message. This will also send an acquire mess handling, but this will wait until this client is finished. Of course you don't know which client will get first, but that doesn't matter, OK? Hopefully.
    [laughter]
    
    Now, the linear logic !  A is if you look at of course A in linear logic is actually really composed of two connective and if you sort it out what t then you see that this is the right logical explanation of what that actually should be. OK. All right, so if you have a shared, in this case, let's say a queue, let's say a shared queue is a frequent thing that you have to implement, then it would have this type, so it's in red, so it's shared. It's an up arrow, so if a process offers that it, it can accept a connection, then it accepts an insert, then an A and then it's going to be released or delete and then you respond with none and then will be released or with some, you send the A and then you release, OK? So we just go back and forth at these critical stages, so now there's a few interesting observations about this. So one is that the section between the up arrow and the down arrow, if you're this way or this way or this way, describes a critical region where you have unique access to the resource.
    Now, for this to work, the types must be what we call equisynchronizing, so if you acquire this queue and it's released back in a different type, it will confuse the clients. Because they don't know what it was acquired and released. And so it has to go back to what it was before so the other client will follow the right protocol, OK? So we have this equisynchronizing constraint on this.
    And once you do that, then certain deadlocks can now arise. So we characterize in this paper actually what kind of deadlocks they can be, but OK, and what I've already said that the sharing in critical regions are manifest in the type. So sharing simply by the fact that these things are read because they're defined to be up arrows, at a critical region because the critical region is just the linear part of the type that's part of your protocol. OK. So going back to the picture at the beginning, why is functional programming so effective? As we said, computation, which is deduction, and we have intuitionistic logic and simple types. And everything is in -- by the way, this down here means that this is open-ended, OK?
    [laughter]
    
    Our work is never done, OK? So what about concurrency. So here is what it looks like, the session types which are due to Honda is this idea that the protocol is described by the types and the processes that satisfy it have to follow this protocol.
    OK, so that was a huge step forward. Unfortunately there's only a small community which paid attention to that, because for example if the developers at Go had known about this or even more likely the developers of Rust, these languages could have been a lot better, but OK, this was kind of a -- wow, few people knew about it, it was 25 years ago already. And then we have the connection to logic so that we actually know that yes, the types are an abstraction of logic and the logic is a perfectly well behaved thing which we can reason in our programs, which is a really nice thing to do but we need to make a small change to the pi-calculus and this is partly because it was derived computationally via the lambda calculus. But it doesn't really work you really need it to work as a primitive for it to work well. And the biggest part of the implementation problems that we have for everything, the session types that is to do with forwarding because it's not something you would anticipate and Milner didn't anticipate it, even though he anticipated many, many other things, because it's not an obvious thing, so it took us a long time to come to grips with how to implement this correctly. So there's a lot of work going on in session types. Not as much as on shared concurrency for sure, but there is some. There is Scribble, which is something on multiparty session type which I won't explain, but you can look at and it's supposed to be an I understand traditional strength tool. So you specify the protocol and it gives you sort of a blueprint for how to write the code that will satisfy the session type specification, then there's other implementations inside the ABCD project, which is led by Simon Gay, Yoshida and Wadler. We have concurrency 0, which you saw, and there's a talk this afternoon in which we at look at.
    I think most importantly what all got me started in all of this was this original paper in 2010. OK, so here is the paper I love which is this Types for Dyadic Interaction by Kohei Honda and sadly he passed away much too young. Thank you very much.
    [applause]
    
    >> Awesome, thank you, Frank, that was amazing and you're around to answer questions and stuff for people here? Cool. Thank you. So the next thing is lunch. People like lunch. As I mentioned again, there's like a big set of food like in the main area right here, but if you want vegan or vegetarian options, you go to the Keel Club, which is down by where the registration is. See you all back at 1:05.
    [Lunch] ... ... ... ... So that's what it's like ...
    >> All right, there are open seats up front so we can get more people in, you know, so we don't have the people in the walls, so you know, find those seats. All right, cool, how is everyone doing? How is everything going? [audience whoops] a couple of things I missed earlier, like one bit of announcement, for those going to Strange Loop and you're looking for more gluten-free meals if you go to the Strange Loop Slack, there's a survey and they'll probably make orders for it so they'll take care of people better in the next couple of days, but a person I wan really want to thank that I meant to thank earlier that helps Papers We Love put all this stuff together, because none of us live in St. Louis is Alex Miller, who runs Strange Loop, so we want to thank Alex Miller...
    [cheers and applause]
    
    ...and the entire Strange Loop organization, they do a lot of great work for us and they help us out so thank you to all of them. 
