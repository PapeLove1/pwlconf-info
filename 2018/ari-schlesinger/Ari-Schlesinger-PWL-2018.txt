    Including Equity in Tech Work
    by Ari Schlesinger
    
    So Ari is here. She's a Ph.D. student at Georgia Tech University, and I came by this work, this is actually a decent job I did of like scouring the internet for interesting papers around -- HCI-based papers around things in tech, and Ari's name came up and I saw some slides she did in a talk and I started reading some of her papers and I was like, yeah, this is the person I really want to have here at Papers We Love. So she does really great work. She'll be talking a lot about it, there's a lot of papers on the site that she mentioned, but I think she'll give a good glimpse of all of these things, so without further ado, Ari Schlesinger.
    >> I'm really excited to be with you and talking with you all today, I think this is a pretty big departure from where we've been but I'm excited about where we want to go, including equity in tech work. so it's not really a secret, we've got some big problems with equity and inclusion in tech. So this picture was taken in 1955. We've got Betty Snyder and Glen Beck in this picture and 55 years ago it was a long time ago, right? We should be way farther in this era than we are right now, but unfortunately we just haven't come as far as we should have. So literally yesterday, Twitter released a new policy on dehumanizing speech, so if you are to be harassed or trolled on Twitter, in up until the end of this year, and you report somebody, it's really just looking for any violations of their terms of service, and that doesn't include harassing language if it doesn't also include a physical threat of violence, like a rape threat or a death threat. That did not come out easily.
    So for a lot of us who have experienced harassment online, it's like yay, they're doing something, finally, after years of waiting. Yesterday this got announced: The problem is so bad we've made ad week, you know, that seems like a weird fit, but I'm sure many people in this room remember the 2016Tay dilemma, when Microsoft's chatbot got racist, misogynistic and anti-Semitic within 24 hours flat. You know, go team!
    2016 incident Google photos tags black people as gorillas and puts pictures in a special folder. This is awful. And just this year we revisited it to find out that they've fixed this probably just taking primates and gorillas out of the system entirely. So you know, that's one way to handle this. I don't think that's fixing the underlying social issues. I don't think -- I would hope that most of you would agree with that attempt, but fixing the underlying social issues, addressing them in tech, that's really thorny. It's really, really complicated. Again this year, algorithms of oppression came out. Are people aware of this book? It's a fabulous book by a professor at USC, and she is in the -- it's there somewhere. But she's in the -- she's at USC. I apparently forgot which school to put in my notes, about you in this book she is looking at the relationships between algorithms and how they reinforce and spread existing social inequalities, and particularly she looks at the relationship between the Google ser engine and women of color. She Googled the term black girls and the first link was very pornographic. That just seems like it shouldn't be that way and since writing this book and working with Google, things have changed a little bit, but the underlying issues still exist. We've got some problems in tech. Some really thorny social problems that we don't have good 0 strategies of dealing with right now. So my hope is that everyone in this room is interested in doing more and doing better, but we get stuck. What does it mean to do more, to do better? How can we address these thorny social problems when we're worried about bugs and did we remember the curly bracket and there's just a lot of things to juggle when you are sitting at your desk and programming. So the goal here is to as a group, own up to some of the problems that we are actively contributing to in the tech industry, whether we are intending to or not, and to look to papers as a guide, as beacon of hope, to help us figure out how do we move forward from here and how do we do it a little better? So we're going to go back to the dawn of time, so we're going to start out better, Hello World, well, not the dawn, dawn of time, but we're going to go back to Unix, so we're going to look at the paper that talks about the origins of Unix, so some fundamental operating system philosophies and race and the logic around race in the US at the turn of the mid century so the 1960s, and after that, as well. So this is a paper by Tara McPherson. there is shows' also a chair at USC. In this take, this paper that we're going to delve into is not originating from a computer science field. So part of what I love about computer science and HCI, my area is that it's interdisciplinary. There's an opportunity to pull in from all these different places and get inspired and work with information sciences, media studies cultural studies, American studies, critical race theory, all sorts of good stuff, but it might be -- there might be some very new material in here for you and I've done my best to scaffold it, but always happy to answer questions if you have any. So this chapter is in a book called Race After the Internet. And without further ado, we can -- it's a 2012 publication, but anyways, let's begin. 
    I figure the best way to set up this book chapter was with a quote from McPherson, reflecting back on it in a 2015 interview. So McPherson says the introduction of computer operating systems at mid-century installed an extreme logic modularity and seriality that black-boxed knowledge in a manner quite similar to emerging logics of racial visibility and racism at the time. We're going to unpack that as we go through the next couple of slides. So before we get any further, we should talk about -- talk about race, because for some people in this room, they have always been aware of race and racism in their lives. There's just no other option. But for other people, this might be one of the first times you're really thinking about race, racism, particularly race and racism in the tech industry and how all these pieces fit together and so if this is something you're interested in, this book is fabulous. So you want to talk about race. She is really just great at writing about this and making it accessible so I highly recommend it. But for us today, the thing for us to remember it isn't a small or easy thing to talk about these questions in a room like this, so I'm just asking that we stay open, because if we want to do better and think about equity in tech work, we have to be open to having conversations about identity, about race, and open to change and growing from these conversations. We really especially need to be listening to the people who are experiencing these problems themselves. We need to be listening to people of color, we need to be listening to people who are experiencing racism day in, day out. So with that stated, let's jump in the way this paper starts, which is juxtaposing two different histories in the US in the mid 1960, we've got a history of computing and a history of social change. So on the computing side, we've got 1965, as a start. I am aware that there's no scale in this timeline, please forgive me. It worked out for spacing of the content, which seemed more important. OK, so MULTICS which stands for multi-flexed information and computing service. It was a very early timeline sharing system and critically it seeds some of the early ideas of modularity and it's really integral to Unix, which when they stopped using it this in 1969, they started developing Unix. And eventually that work resulted in a Turing Award, so got a reference to some Turing Award winners in this talk, too. So that's sort of the mid century in computing history. On the other side, we've got US social change. In 1965, we've got the assassination of Malcolm X, we've got the voting rights act, we've got the united farm workers being established, huge union, in 1968, the assassination of MLK, Stonewall riots, the American Indian movement, so AIM is established. These are some major cultural milestones in this country. And abroad big things were happening, as well. Continuing the Chinese cultural movement. The black panthers were founded in 1966. A lot is going on. Typically we're siloed. These histories are sort of modular. We don't think about them in the ways we might be interacting, and the ways they influence each other, but history is overlapped, right? These things were happening at the same time. People acting in this moment, no matter where they fall in the political spectrum, were influenced by the world they were living in by the changes that were happening. And so what Tara McPherson does, is she puts these two things in the conversation with each other, and looks at how the larger ideologies shaping thought at the time are connected across them. So these two lineages are interconnected, and if it doesn't seem like it yet, we're going to get into the details of how she brings them together, but importantly they are both shaping thought and knowledge in the 1960, and they're both doing it in some very similar ways, so McPherson says they're both existing as an operating system of sorts, right, so you've got two slices of history, the development of dominant computing philosophies, and major cultural and global philosophies are changing, as well, cultural in the US, and so one way to think about operating systems here is to think about them as a unifying framework for organizing, managing, and prioritizing things. There's a lot of control in input and output both on the computing side and on the social change side. So one of the things these two operating systems have in common in the mid century is modularity. Right? So built on this idea of discrete things, objects, if you will, that could be put together and taken apart and deleted and added and changed with no impact on the rest of the system. If it is well done and it is thoroughly modular, it shouldn't matter. And it seems sort of obvious for the Unix stuff, right, but McPherson does a really good job of arguing how it's also operating in the way that the US is thinking about acting on -- and operating within racial logics at this particular moment in history. So this knowledge system of modularity, a place for everything and everything in its place, has some very, very widespread consequences, right? Modularity becomes known as good design.
    So let's start with the stuff I think we are all sort of on top of, which is Unix, I think it will be easier to go from there than jump in the other way. So everybody here knows Unix, yeah? Yeah, OK.
    So it's a powerful idea. There's a whole like philosophy that comes out of it, not every computing concept ends up with a philosophy that people associate with it. So that's huge. And you know, modularity is a big part of that, and so you can't really do too much with modularity without at least pointing to Parnas and this paper on the criteria to be used on the in decomposing systems into modules. So we're laying down the terms and solidifying movements that were sort of already under way in computing, right? This paper is 1972. So in the McPherson's book chapter, she goes farther into depth on some of the details of the Unix system, but I'm going to leave that out because if you're interested in it you should message me and I'll totally send it to you. So McPherson turns to the tome the art of Unix programming by Eric Raymond, famous open source software evangelist, who is famous for the publications under the cathedral, if anyone is familiar with those, and McPherson points out to the first 9 rules ever Unix that are published right in the beginning of the book and the very first of those rules is the rule of modularity. So I don't think I have to convince you if you look back to the texts that we write and the stories that we tell about those fields, you can see that it's in that history, too, it's not written down. Not just lived in our lives.
    But we're going to focus in here on modularity. So to be clear, McPherson is not critiquing modularity, and in temperatures its usefulness in a computing context, right? There's no doubt that it is helpful, right? Keeping things minimizing complexity and keeping things discrete so that you can identify and isolate problems, that you can work on one thing at a time so you don't have to juggle everything in your mind at once is hugely wonderful when you are programming, but this type of logic, this operating system, underscores a weird -- a whole world view, and part of that world view is that when something is troublesome, it's modular, it's. And that's a really important thing to keep in mind as we talk through some of this, so I didn't have to convince you, but there it is, modularity is foundational in Unix.
    So if we move on to race, I think it's probably particularly from the backgrounds in this room not as clear how this happened, so before we get into the particularities with modularity and race in the 1960s, in the US, I want to just give a brief background on some of the scholars that McPherson is pulling from, so she's pulling from omney and Wynette who are sociologists primarily and Omney and Wynette say that racial formations serve as fundamental organizing principles of social relations in the United States. So we're talking about really big ideas of who do we know, how do we talk with people, how do we judge people? Is it instant, is it implicit, is it explicit. So there's a lot going on here, and so during this mid century moment, we are moving from the Jim Crow era to the color-blind era, where people are pulling themselves up by their own bootstraps the merit of who they are and so she's stating that the push towards modularity and the covert in digital -- well, sorry, struggling over my own words here. Or her words, but the push towards modularity and the covert in digital computation also reflects changes in organizing social life in the 1960s, right? So we were talking earlier about the assassination of Malcolm X and of MLK, we have the voting rights act and the Civil Rights Act. This is race is a really critical part of all of them. And so when we tie operating systems to these, we get organizing options of thought, belief and action. So McPherson says in the first half of the 20th Century, laid bare its racial logics, things like only whites in the south, Jim Crow laws, in the second half it increasingly hides its racial kernel. So there's an intentional word choice there. The core most basic operating systems, some things that are invisible to so many of us if we are not actively involved in pulling them apart and understanding them.
    So you might think that that was then, this is now. But McPherson also takes us to segregation as a way to demonstrate how these logics are the logics of modularity don't just pop up in our racial understandings at the mid century, but they continue to make an impact, so this up on the slide is a pretty up to date map of segregation in the Chicago metro area, we've got blue dots representing black communities, red represents white and yellow represents Latinx communities. Following these movements, segregation in many urban areas became worse or it didn't improve. Look at Chicago, that's very segregated. And so McPherson places the idea of segregation into a relationship with modularity. She is talking about how there's a different inflection, when you think about modularity in segregation, that there are easily removable or containable troubling pieces, that you can sort of relegate people to the crumbling urban centers and leave them and you don't have to think about it in terms of the rest of your life. You don't have to live that life, you don't have to walk through that part of town. There was that app somebody made about avoiding sketchy neighborhoods. Do people remember that? So modularity is a part of the way that we construct and think through and talk about race with the turn of the -- not the turn of the century, but in the mid century. I keep wanting to say turn.
    So, OK, we've talked about Unix and modularity and we've talked about race and modularity. Let's bring these two systems back into view together, because one of the things about modularity is that they're discrete, it's really hard to -- like foundationally pushing against these idea of these pieces together. So McPherson says that modularity in software design was meant to decrease global complexity and clearly separate one neighbor from another and that's from Raymond when put in juxtaposition with segregation is striking. At least I find it striking. And so these strategies also played out in the ongoing reorganization of the political field throughout the '60s, and '70s, it played out in the way that we think about race and we think about identity in this country. So OK. How we doing? Yeah? OK. Cool. Figured I'd check in. It's a lot of material.
    OK, he so coming from this interdisciplinary space, looking at media studies, cultural studies etc., computers aren't just fancy calculators, not that they're fancy calculators -- well, you could still call them that still. They do a lot of that. But they're also cultural encoding machines. They communicate and convey our values. So she's not arguing that coders creating Unix were consciously creating some way to think about race as something that's past and box it off and move it away, put it in a black box, or consciously coding racial logics into our digital systems. Rather, she's highlighting the ways in which she is systems, these histories, these internal logics, these operating systems, are connected. Both in computing and struggles for racial justice at the time. So the question then is, OK, maybe you buy it, maybe you don't. If you don't buy t please give the paper a chance. Stuff she covers for the sake of time I did not. But how do we move forward here? If we're going to face up to the problems that we're contributing to, if these modular logics are making it hard for us to address these complicated social problems, what can we do? So McPherson calls for new hybrid practices of the things that she lists. One of them is critical race theory coders, this idea that more of us need to be exploring a wider set of interdisciplinary ideas and listening and talk with people outside of her normal purview, or maybe there's somebody who's in your everyday life who is not being listened to because of these larger systems, and centering those problems, and really owning up to our role in it and trying to do something about it, so it's a nice vision for where we can go from here. But before we move on, I want to talk about how these connected operating systems are really prevalent, not just in the examples I've talked about so far. And so I'm going to talk about modularity around oppressive systems like racist logics in the law, in the United States. And coincidentally also around the mid century. So I want to go to a another paper, this one is by Kimberle Crenshaw, if you've ever heard the term intersectionality, this is the paper with coining that particular term, and so Crenshaw is a profession of law at UCLA in and Columbia and she's looking for creating a frame for us for thinking through multiple types of oppressive systems and how they interact at same time. So how does racism and sexism interact? And what does that mean for people experiencing both of them at the same time. So this is to think about them as a literal intersection. Instead of you have racism in one box and sexism in another box and they're discrete objects that you can deal with one, deal with the other, not ever have to worry about how they overlap, that is -- it doesn't work, and unfortunately that modular logic is encoded in the law, and so part of what Crenshaw talks about is a case Degraff and Reed versus general motors, it was a case where five black women sued General Motors because they tall got fired on a last hired, first fired principle but part of what's important to know is that General Motors didn't hire any black women before 1970, so it's not surprising that there was this large group of people that may have been the last to be hired. Seems like it might have been related to those social changes we've been talking about in the 1960s, so these women took their case to court and the judge dismissed it flat out. And here was the reasoning: General motors still hired women. There was no discrimination case based on women, because white women were still working for general motors. And there are still black men hired by General Motors. So there might be some other issue that you can join some other case, but ultimately the judge is saying to these women that they're asking for special protections that they can't be discriminated against at the same time for being black and women.
    I mean that to me is like modularity in a social system perfectly described, and so looking back on it, it's, you know,ile heartbreaking to think that there was no case because that's not how the law was designed. You're either struggling under sexism or racism but you aren't at the intersections. So I find intersectionality to be a really helpful framing system because it's not just one thing that we're dealing with. The mod layered and the chaos of social life doesn't really work that way and while it's complicated to grapple with all of these different things, it's super-important. Right? Because this intersection is not too bad, you know, even this one is simple. There are so many various modes of systematic, systemic oppression that are -- that we're all navigating through. We've got homophobia, racism, sexism, ableism, classism, there's various types of nationalism, all sorts of religious discrimination, there are so many overlaps there, right? Gender itself is a really complicated field. Like so many think there's just a gender binary, we've got just men and just women and even that is false logic to put it one way.
    So that's like a lot to take in when you're trying to figure out, OK, I want to do better. Tech shouldn't be so bad about these equity and inclusion issues and I want to help, but where do I begin? , you know, we can all get overwhelmed trying to tackle these problems. So this is where I've got good news for you. Look at all the coffee cups, there's so many people at the table. For me this is where I turn to words and listening to people and there's so much inspiration to be had. So many ideas that have pointed out like Crenshaw and McPherson point out. That help us point toward better futures. Not perfect futures, we can do better, one step in front of the other, right? So what I want to do now, is well, I've got plenty of time, I don't want to overwhelm, so I've got some fly-by papers that I wanted to point to in terms of people who are doing this type of work of bringing the social and the tech together. And trying to help us navigate the next step forward, and it won't surprise you that I'm in HCI. A lot of these papers are in HCI, human-computer interaction and part of the problem if you're looking at human social problems and computer problems, if you're looking at them together, it's a pretty good fix so even if you're not an HCI person, give it a chance as a place for inspiration, because it's a really good nexus point for these types of ideas. So this first paper I want to point everybody to is called design justice towards an intersectional feminist framework for design theory and practice, it is by Costanza-Chock. They are a faculty associate at the Beckman Kline Institute at Harvard, as well, and this paper does a really great job of saying, OK, you're doing the work of designing, you're sitting down and trying to think of how do you progress and what does it mean to wrestle with all of these different systems? And this is a brand new paper, came out just a few months ago, and Sasha is helping guide the way, helping us think about what are our complicities in these systems and what does it mean to be wrestling with them? So someone else who is doing great work is Alex Ahmed. Alex is a FHD student at northeastern in the personal health informatics program. And this paper, trans competent Interaction Design ... Does a fabulous job of outlining how our assumptions, when we're programming, about gender binaries, end up having really frustrating negative impacts on people. And through this interview-based study, we get to hear the voices of people who are impacted and really wrestle with the implications of that and center those voices and Alex leaves us with some opportunities for where to go from a here, but these are just starting points. All of these things are stepping stones. So you won't find exactly what to do, but when you're open to these ideas and you let them transform your thinking, who knows what we as a group can come up when we're centering these voices. There's a lot of hopeful potential here. This next one is it one of my papers. It's called Let's Talk About Race. That might be surprising. But it's actually different and it's about chatbots. So we start off with Tay and look into the particular technical reasons why it is hard to program in a way that is responding to racism. Right? So when the Tay fiasco happened, there were a lot of think pieces that came out and some people were just like, you know what, racism is bad design. You can fix racism in technology through designing well.
    and so, OK, how? Right that seems like a huge problem, like a huge insurmountable task and so what would it mean to try and do better when programming an AI chatbot along these types of issues, and so in that paper, we look into sort of three technical contexts that are important in chatbots, we look at database, we look at natural language processing, and we look at machine learning sort of broadly and we map similarly to McPherson's, but in a more tech space, right, so a CI paper, rather than a digital humanities space. So we are trying to bring these pieces together to understand why these problems are so hard for us to address, and then say, OK if we know that the way that the technical issues are related to the social issues, we can understand why we're getting stuck, we can name the problems we're facing and then we can try to do better. Google two years later is still struggling with the gorilla thing. Two years later I'd be happy to be wrong but I'd be shocked if we've progressed a lot, unless all of us say, you know what, yeah, we're all working on this now and this is a priority. So I think these are some inspiring papers to turn to, but coming back down to the here and now as opposed to the hopeful tomorrow, where are we now, right? Relative to that picture we started with, from 1955, how far have we come? And so this got released earlier this month. I don't know if many of you saw this, but Melinda Gates' new research reveals alarming diversity numbers. And it's not just diversity numbers in hiring practices, and in, you know, computer science and engineering degrees, I think a lot of us know about that, but this is also looking at the spending habits of some major tech corporations. So this came out September 12th, not very long ago, and in this report, which is done in partnership with McKinsey and it's titled: Reboot Representation. They look at 32 large tech corporations, including Google, eBay, SalesForce, some small names you may never have heard of, and they look at how much money these companies have brought in in the last year, so the answer is around $500 billion in sales, they look at spending in philanthropy. That number is a little more than $500 million. And then they break down that number even more. And they say, OK, so these tech related problems, these including diversity and justice and computing, how are we doing there and we look at money. A lot of people say looking at the money. So $24 million of that money went to supporting programming women and girls in tech. 24 million. So when we look at intersections, when we say these things aren't modular, it's not just women and girls, how are we doing when it comes to women of color in tech? Across these 32 companies, they spent $335,000 on women of color:
    So if we don't look at this, we might not even be responding to these, that seems horrible and how is this so many years from 1955? We can do better than this. So if you turn to papers for inspiration, this is not shocking that this is what the numbers look like. So I've got some papers if this is something you're interested in looking A this first one is when computers were women. It's by Jennifer Light. And Jennifer Light is professor at MIT and this paper looks at the historical portrayal or the lack thereafter of women in science. And I'll say right off the bat if there's any professors in the room, I think this particular paper belongs on computer science curriculums everywhere. Undergrad, grad. It's a really accessible paper, and you know, some people still don't know that once upon a time, computers were women.
    Right like, it wasn't always a machine. You used to have people sitting down and doing tabulations. I think more people are aware of that now that we've got Hidden Figures, but it's important to see what's happening there so in this paper, Light looks at pictures and job ads and takes a historical point of view and you see how pictures that were in newspapers of the ENeac system cut women out. It is a great piece. Highly recommend it. It is very accessible for the audiences that you might be interacting with. So similarly, and this one comes out before is another paper called the army and the microworld. And this one is about the computer and politics of gender identity. And the other one, Light's paper -- this one speaks to male computing and masculinization of the -- you have a pretty good record of some of the labor politics, particularly along the gender lines, in computing and it makes this headline not particularly shocking. Particularly since race is barely even a part of those two papers and if you have the framework, the ability to name problems and see them, like intersectionality, you see these gaps. You see these margins and these holes that people are falling into, and so sometimes that can make you feel kind of like this, you know. Grrr, that's such an underwhelming, there's so much more anger. But you get tired. You know, there's a lot of anger and rightfully justified anger. So be angry.Ites really important. Get riled up. But don't forget. Papers. Lots of them. They have inspiration for us. And not just papers, but movies, music, so much art, really listening, particularly to people who are experiencing these social problems you know, on the front lines every day. If you're listening, if you're reading, you know, paying attention to who you read, like citational practices as an academic are really important. How many people of color are you citing, how many white dudes are you citing? How many women, how many various gender identities? How many people with different abilities. there's -- our citational practices, the future's not determined yet. You know, we can change it. there's a lot. We hold a lot of power. We are the populous, means of production. Go us. If we're willing and able and ready, right? So so really important here, is that moving forward, we need to be willing to change and self-reflection. So I don't know how many of you good a women and jeopardy race, a Chicano class, or maybe even an English class and you're like, what do I do with all this information? I'm worked up and I don't know what to do with it here and maybe your professor says, well, you're changed now. I remember being frustrated with that, but it's correct!   If you open yourself to really being moved by people's ideas, by reflecting on how they make you uncomfortable, by where you have get stuck, by what you didn't know, and how much you were missing, we can grow, and when we grow, we can make new choices. So, you know, there's hope, we can do better in understanding equity and inclusion and justice and centering the voices and of people who are experiencing these problems every day. So I like to leave with a question to really -- I think it's important to have an opportunity to do some self-reflection, and so I pose to you this question: How does the tech we build, how does the tech you contribute to benefit some people while further harming others? Because when we can confront our own involvement in these problems, there's a lot of potential for how we can move on from here, and so it's a reminder that in moving forward, we need to be centering the people and the intersections in our processes, right? Like I'm happy to be here talking to you, but I am not the foremost authority on all of these problems. We got to start somewhere and then keep going from here. It's about meaningful inclusion. So you don't, I don't know if you are familiar with some of the critiques of universities and companies and how they do performative diversity. Look at all these tokens, these very particular groups of people, we've put them on all of our ads, we've got them in all of our promotional material, look at how diverse we are, but that's performative. What about meaningful inclusion? What does it mean to step back and listen? To be open? So I find that papers and music and movies and listening to the voices, particularly of people of color, of women of color, of queer women of color, of disabled people, of disabled queer women of color, absorbing and just being open to their voices and then really respecting where they come from. That's a path towards understanding what it is to have meaningful inclusion, rather than performative inclusion. So as I was saying, in our fields we tell stories, we have historical stories and the stories we tell through our citational practices, who we know, who we listen to, they sort of set up the future of our work, right? 
    Adrienne Marie Brown is an awesome organizer, and she writes about if you're thinking about the stories you tell, if you're thinking about the future, you are participating in science fiction, and it's an opportunity for us to create new futures, multiple new futures, futures that work for more people, that were envisioned by more people, not just the narrow set of people who might have written the story so far. But hopefully we can take these types of reflections and come up with some new stories to tell about where we're going to go in tech. What it means to include people more meaningfully in our work. So that is the note I'd like to leave you on. I think the future is bright if we are open and willing to listen and to invest in making some material changes, if you are interested in this topic, I would love to keep chatting with you. I find it really exciting. I think there's a lot to dig into in getting into the particularities of tech and the particularities of social change, so I'd look forward to hearing from you. And thank you all so much.
    [applause]
    
    >> Thank you, Ari, that was awesome. Thank you. Our next talk will be at 2:05. So you get a little bit of a few minutes of a break.
    [break]
    
