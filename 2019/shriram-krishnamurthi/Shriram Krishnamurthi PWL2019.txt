    All right!, that's really loud. How's everybody doing?
     AUDIENCE:  Whoo hoo!
    [applause]
    
    It's already like post-morning, right? So now you have time to think about papers and research and good ideas, right? So first off, I'll just do it right now, but the wifi is having problems but you've heard that at every conf ever, so we know about it, so that's on the way. This is the fourth Papers We Love conference in a row, which is pretty cool. Yeah, that's pretty cool.
    
    [applause]
    Which, you know, I was telling Darren, one of the other founders and organizers of Papers We Love, that at four you're starting to feel like, all right, this has become old hat, we're doing it, and you know, things have gone pretty smooth so far, and we're pretty happen by about that, but most of it is because of all of you coming here for the fourth time. So who here has been to other Papers We Love conferences before? Wow, that's pretty cool. First time here? Also pretty cool. Who's been to Papers We Love chapters in their local communities and stuff like that? Awesome, cool, well, thank you from us, because we wouldn't even do this if it wasn't for all of you all coming out and I think to a big -- one thing I do want to get an applause for is what really makes Papers We Love and all the communities that come together to talk about papers and research and do different variations and forms of showcasing that, it's really all about the chapters that come together so we can put this thing together. So thank you to all of the organizers and people who put Papers We Love together, so
    [applause]
    
    So for the conference, we're super thankful to have all of our sponsors this year. They've been playing up on the slideshow that's gone around. Actually for a lot of theer we're getting respite sponsors, and in particular I want to thank Two Sigma who gave us one of our level sponsorships, but are also sponsoring the captioning that's going on on, which is from Norma over here and you can talk to her about all her work and if you want to see stuff, it's over there. So if you want to move that way, this is a good time to do that we want to thank the ACM, who gave us a lot of swag and pens and notebooks, we did socks this year for our thing, but they gave notebooks anyway, which is pretty cool and they do have a thing -- you can talk to one of the organizers, there's a link to get three months of ACM membership and get the magazine and access to papers and download everything in three months.
    [laughter]
    That's how it works, create your own archive. But we're really thank you, so thank you to our sponsors.
    [applause]
    
    So one thing to be aware of, we do have a code of conduct that is on the website, it's also, we also have a very similar version of it running in the GitHub repository for Papers We Love. But please check out the website to look at T it talks about also the photo policy which you might also know about that you're wearing certain colored lanyards but it's up there and you can contact any one of us, and this year you can know who is an organizer because we're saying it on our shirts this year. So you can find us. We also have the Slack channels, both on the Strange Loop Slack and on the Papers We Love Slack. We have emails that we sent around if something comes up and you want ta tuck to us. That goes for everything kind of here at Strange Loop and all of the chat channels and all of those things that exist. So a couple more small items: Lunch. Does everybody have their lunch ticket? If you don't, or if you've lost yours, we have lunch tickets at the front. That person, David Ashby, has lunch tickets around, as well, and he is the kind of lunch lead and liaison for today, so you know, get your free lunch. We do have three trucks that will be outside. Not right out here because they have cement here right now but outside the main hallway and outside those doors, and we'll have people leading you there. One of the trucks caters to vegan, vegetarian, gluten-free diets and one of the others has some of it and the other one doesn't have any of that at all. There's kind of preset menus for you when you have the lunch ticket. You have to show the ticket. It's very important. OK. Otherwise, the bathrooms are under the stairs as one more logistic thing and does that cover everything there? Very cool. Mostly thank you to the organizers, who put Papers We Love Conf together, as well, so that's a huge thing.
    [applause]
    
    
    There was also a URL for the caption, right?
    >> There is a URL fort captions. We did have it up. We'll put it in the Slack. Yeah. We have it in the Slack. We'll put it up again, but we do have a URL for the captions and if you have friends who are not here, even though it's not livestreaming, they can look at the captions and they can go, I wish I was here!  And actually, I think, to lead to the first speakerrer, Shriram Krishnamurthi, a lot of it when I curate the papers is what would I want to see if I go to a conference and I think the speakers that we curated this year put together what I think is a great conference and particularly for me, I got kind of a class with him and a bunch of other professors in Utah at this Racket school of semantics, it was an amazing time. And I actually liked Salt Lake City a lot more than I thought I would. It was a class that we have Shriram, and all of these other great professors, it was vibrant. I learned a ton just in one week. So I'm kind of pitching the Racket School stuff so you should take a look at that on your own accord. But I've known Shriram's work for a while, but having actually been in a class with him, seeing him speak, making sure that we don't use vocabulary around programming in a way that people don't understand it and understanding it well, so he's a great communicator, he's talking about a great paper that influenced him but he's a great communicator. Anyway we're so happy to have Shriram and happy to have him lead this off, so thank you.
    [applause]
    
    
    >> No high expectations, let's see if we can live up to that. Hello, I am Shriram, this work that I'm presenting is most assuredly not mine. I will do my best to not lapse and talk as if it's mine. I'm not wearing a lanyard, because apparently it's interfearing with the audio and that's more important. I am a green lanyard. What is this paper about? It's got this absolutely obscure-looking title. The actual author's photograph is up there. That's Matthias Felleisen, what is this paper about? There's a lot of things that we know about what can and can't be done in different computational models, right? So we have very sharp mathematical distinctions, depending on who taught it, a course on theory of computation, you know that there's these very fine-grain distinctions we know how to draw and so these are actually useful to us as a language designer, this is invaluable to me if I design languages. I think if I add this, what does my textbook theory tell me might happen? Is that a consequence I'm OK with? I exploit the fact that I can live inside small languages that have limited computational power so I can do very rich things with those languages, OK? I've made a living off of this, it's been good. Unfortunately, we hit this point, this sort of a Turing threshold, OK, and beyond which like everything is equal, and when everything's equal, we can't make any meaningful distinctions and when you can't make meaningful distinction, I can't rely on this toolkit that's really useful as a language designer, verification engineering and so on, OK? And that's what this paper is b and if none of that meant much to you, that's perfectly OK because we're going to spend the next 49 minutes unpeeling all of that, OK? Good.
    I want to take a moment to tell you a little bit of personal history with this paper. I was a computational biologist and I had the misfortune of having early success, my Imposter Syndrome kicked in in a big way. People are going to figure out I don't know any biology. Late success, OK, you can sort of learn stuff later on. Early success is really bad. So I look around and I say what is a computer science thing I can do. I don't even know how I found this paper. I remember the afternoon I read it and it was one of the most amazing days of my entire life, OK? I still have the soft glow about that afternoon sitting in a Houston apartment reading this paper.
    So that's why when Zeeshan contacted me, I said I know which paper I'm going to present. To be quite honest I had not read this paper literal any a 20eer years. I got stuck on the proof. You know, it's called Papers We Love, not papers we used to love. But it's all good. I love it all over again, and this opportunity helped me fall in love with it all over again, OK? So just one last personal thing: I asked Matthias for a photograph of himself from the time this paper was written and he sept me this. So this is about 1991. That's Matthias on the right. The person on the left is named Bruce. It's personally meaningful to me. But Bruce was also very influentiala Matthias constructing this theory he's acknowledged very prominently in the paper. So really there's a little bit of Bruce's spirit in here, as well. That's the end of the permanent stuff. Ready to get going? OK, what is expressive? Well, I could tell you, but you know what's even better? You could tell me. So I'm going to run this kind of like I run my classes. Might work, might not work, let's give it a try. So I would like you to turn to your neighbor if you don't mind, if you don't have any anxiety about this, turn to a neighbor and introduce yourself, make a friend, all right, go!
    (Audience chatter)
    OK, we're back, we're back, we're back. Good. So here's what's going to happen. We're back. We're going to vote. The way we're going to vote is -- so there's lots of ways of voting. We can raise hands. The problem I don't like is raising hands is you feel bad if you don't get the right answer, it's like everyone is going to see that you've raised your hand. So instead we're going to hum. Can you all hum? Very good. Don't worry, we worked it out with closed captioning, we're totally on top of this. If you're aud ally impaired by it's all there. I'm going to show you a series of things that are going to look like this. There's interesting going some language L and then I'm going to add some feature F to it. Language L, feature F. You're going to talk to your neighbors and decide whether you think this is an expressive addition to L and also why, you know, yes or no, everything is yes or no, is that good? We're clear on the rules of the game? Any questions if if you understand the rules of the game, hum, if you don't understand the rules of the game, hum. Good.
    OK, very good. So let's start. Here's our first, OK? I have a language that has no loops and no functions and I'm going to add loops to T OK, talk to your neighbors. Ten seconds 8, 7, 6, 5, 4, 3, 2, 1.
    We're back!   OK, how many of you think this adds expressive power?
    (Low hum.
    How many of you think it does not? (Low hum.
    Oh, interesting, why do you think it does?
     AUDIENCE:  You could add confusion, OK, that doesn't sound like expressive power to me.
    OK, so classic result from computational theory that once we start adding loops, we start adding expressive power. OK, next question:
    I have a while language that only has while loops and now I add for loops to it. How many of you think yes? How many of you think no? (Hum)
    Why do you think no? Why do you think not? Oh!  You can rewrite, I heard the word rewrite. You can rewrite one of those things into the other. We like that answer? Very good. OK, next one.
    For loops: I add while. How many of you yes?
    How many of you no? Oh, wait, that's (why not? Why not?
    Oh, you might have some intuition in your head, oh, well, while loops are unbounded, for loops are bounded, so if you already have while, I can add for. You see you're starting to form a little intuition here for what's going on? Next one: I have a regular language and I have context-free grammars.
    I know, I know. This is exactly the kind of offensive thing programming languages do. OK, OK, very good. Very good. I will refrain from stating an opinion on this.
    Next. I have a two-armed if and I add a multiarmed if. I can have lot of ifs, else, else, else, if, yeah. Yes? No? No, OK, why is it a no?
    You can rewrite it again. I heard the word rewrite. You can just translate these into the other, OK? OK, good. I have a pure language and I add state. Oh, Ho!
    
    [laughter]
    How many for a yes? How many for a no? (Hum louder)
    OK, interesting. Why not? Carry the world, state, monad, I'm not sure what those mean. I this they have something to do with the food trucks at lunch, burritos and stuff, OK.
    I have two more. I have a language that has a binary -and I'm going to add a unary .
    Why in rewrite. Everyone is using the R word now. Rewrite.
    I have a language without exceptions and I'm going to add a halt operation. How do you feel about that?
    
     AUDIENCE:  It needs to catch fire.
    No, I stated the problem. You can give your problem later on, OK? OK, how do we feel about this? Yes? Yes? Oh, interesting, no? OK, dead heat. That means you need to stick around for the rest of this talk. Very good.
    OK, so here is our general issue, OK? We have some language L and we have some feature F, and what we want to know is does the addition of F add expressive power to L?
    Right? That's our problem.
    And all of you seem to have some sort of intuition, thankfully your intuition corresponds to what I expected it to be, otherwise this talk would be quickly about to go off the rails, kind of like the St. Louis rail system. I guess.
    Then if we can translate or pile the LL & F down to L. F is probably not expressive.
    OK, very good. If this is your feeling, then there are two dudes who would like to have a word with you. OK? These two dudes, OK? If you don't recognize who they are, that's OK, their names are JavaScript and x86, OK
    [laughter]
    I'm kidding, I'm kidding. The guy on the right is Benedict Cumberbatch, the guy on the left -- you know what, let's call it Leonardo de cap Rio. oh, no, no, that's Church and Turing.
    So what's the thing? So church and Turing have a hypothesis. Basically says, look, you can compile things, you can compile all kinds of things into all kinds of things, and you know this you run programs on x86s, you run programs on JavaScript. Everything is intercompilable to everything else. And this is actually the problem, so until we get up to the point of being able to express what are called universal languages, Church-Turing hypothesis. When you have regular languages, context-free languages, there's a lot of crisp mathematics that says one of these things is more powerful than other. Adding it adds expressive power, OK, whole theory textbooks devoted to this idea. They look boring as hell, but they're actually beautiful.
    Worth reading, worth understanding, right? But when we get to Turing, we're like, oh, heh, it's all good, it's all the same. But as programmers that's not what we think. You think, every language is the same. Why do we have a Elm Conf, why do we have Strange Loop? It's all a matter of opinion. And am I trying to start a religious war? That's what it turns into. So the question is, are we without any mathematics at all and that is the genius of this paper. It lets us escape this phrase, the Turing tar-pit. That Perlis used. It turns out that we can actually use mathematics, to draw mathematical distinctions between things.
    That's what this paper is about and that's what this talk is going to try to convey to you. And if that's not interesting, we can leave there.
    So I sort of suckered you into saying the intuition is something about translation compilation and then I got you stuck in a tar pit, right? I put you in the Turing tar pit. But if you think about intuition for a moment it's not exactbly what I said. I think your intuition was a little different. Your intuition was more like I can locally rewrite it, right? I can just do a local transformation. If I have this multiarmed if, I can turn it into a sequence of single-armed ifs. If I have a for loop, I can turn the for loop into I'm going to introduce the variable and then I'm going to do a while loop over that variable until I come to the terminating point, right? It's a local rewrite. That's your real intuition, right? That's why you're like, ah, this is not an interesting feature. I can write a keystroke in my editor and boom off it goes and expands everything away, right? That's your real intuition.
    So essentially your intuition is roughly speaking, it's like single Lispy macros.
    [laughter]
    OK, good, now that I have you where I want you. I like to think of it as a Las Vegas principle, so what that means is what happens inside parentheses stays inside parentheses.
    Now just to be clear, this is not a talk about Lisp in any way. If you look at Python, for example, in Python, there is actually desugaring going on. x + 2 is that. Haskell has desugaring, right? I have it's not a prefix, parentheses talk at all. It's just the idea of doing programmed rewriting locally, that's all. OK? We're good? All on the same page? All right, good.
    So let's now go back to talking about pressiveness. When there's two sides to this, right? So I've got L and I've got L + F and what I want to know is F not expressive? How would I say F is not expressive relative to L? What would it take? What would you have to do? Yell it out. Show me a macro, right? Show me the macro, just give me the macro and we're done, right? It's really simple. It's actually a more subtle than that. Because you might be writing the macro, but you're really wrong. So let's assume I have a semantics for both of the languages, OK? Let's take every possible program P in the bigger language, let's expand out that program, OK? And now I want to say that these two programs have the same meaning, they're somehow the same. That's implicitly what we want, right? We're good. Little notation on the screen, but hopefully the words are enough to get you through the notation, right? Hold that thought for a moment. Now let's ask a question: What does it mean for F to be expressive relative to L? What does it mean to this new feature to be expressive relative to this existing language? Oh, you can't just give me a macro for that. You need to show that there cannot exist a macro, right? There cannot possibly exist a macro, in like beyond the scope of your imagination, but none of our imaginations, that's a pretty big ask. That's the interesting part of this paper, OK? Showing that there cannot be such a macro, OK? But both parts of this paper rely on some notion of equality. Some definition of equality.
    OK? Now, I have a question so let's take a vote again, right? We have a choice: We can hand-wave the question of equality or I can tell you why equality is an interesting question. It's just equality, right? Equal sign. So how many of you want to hand-wave, why is equality interesting? How many of you want to know why equality is interesting? Good, because I did not prepare the other talk.
    OK. So
    [laughter]
    Equality is hard, OK, but before I go into this, there's always going to be some person in the audience, right, wandered over from ICFP, wandered into the wrong room or something like that, and I need to say to you, everything I'm going to say for the rest of the talk has a giant asterisk on it. So there are all kinds of words that you'll see in the formal definitions about capture-free substitutions, etc., etc., I'm going to leave all of them out.
    Now, are they important? Yes. Usually they are important for making the mathematics work out. Sometimes they're extremely important because they really change the meaning of things. Sometimes they also provide insight, but doing all of that is outside the scope of this talk. When you read these papers, pay some attention to these phrases, basically if you think aha, I found a counter example, it's probably because one of these phrases I left out and that phrase covers this case.
    So I see people!  Behave yourselves now
    [laughter]
    I said equality is hard. Hopefully you're not a bunch of academics but like programmers which means you're skeptical of this claim. So you should be appropriately skeptical every time an academic says something. So here's a counterpoint: Equality is easy. I could do something really simple, I run e1, and I run e2 and I compare the answers, right? OK, done. Ha!
    Is there a thing on the board that should trouble you?
    [laughter]
    What's the word that should trouble you?
    Compare, because I turned the equal into compare. I haven't solved the problem, really. Why is comparison hard? You compare all the time, right? You right test suites, they compare. Now, anyone who has really written a test suite knows why equality is hard. Right? But let's think about comparison for a time. What do we mean? String equality? Are these two things equal? Not equal? Are we getting into philosophical discussions about, you know, numbers? What if my output is actually a function. I get these two lambda terms? Are they not syntactically equal? What are we going to do send it out on Mechanical Turk and ask someone?
    What if any expression has free variables in it, you can't even run it? How you going to run an expression with free variables? You can't do that. What closures? What about things like timing? Anybody who's ever dealt in the crypto world knows that these are extremely relevant questions because this is how you break crypto, right? it's really about equality. You think you have these -- and information is revealed.
    Not only are these crypto problems, not only are these kind of theory world problems, every compiler writer has to deal with this because when a compiler writer optimizes something, they're replacing one expression with another expression. They better have those two expressions be the same, OK? So it's a very compelling problem. So equality is actually hard. OK.
    Now there's this absolutely brilliant definition that is used in the literature and I want to step through this definition with you, OK? It's a term called observational or operational equivalence.
    And you may have run into it before. If you've run into it and it made perfect sense, great, if you've run into it and it didn't make any sense at all, that may be an appropriate response, because it's quite subtle and there's all this unwritten text and like theory that they never tell you. So I'm glad the door is closed because I'm going to tell you, OK? Now, this comes from Jim Morris' dissertation and essentially it's not how it's phrased but this is the question it's asking. Is there a way in the language of telling two things apart? If there is a way in the language of telling them apart, they're not equal. If there is no way of telling them apart, they are equal, OK? Because if there's anyway at all of telling them apart, someday, some programmer might use that way of telling them apart and now these things are not equal, right? This is what a -- so does that make sense. ? I'm going to drill down hoo frere. Let's say we have a language like this. You don't have to follow the grammar, it's just some lambda calculus-like language, OK? And the question is what are all the ways of using a piece of code? It's essentially all the ways I can surround a program with more code. Those are the ways of using the code, right? So we're going to call this a context, so context is I've got some junk of code with a hole in the middle of it and that hole is where other expressions can go. So here's an example of a context: + 1, halt, so that's a context that adds 1 to something, so it takes one piece of code and uses it in a context that's adding 1 to it.
    That's what a context is, basically it's a chunk of code sitting in it that can if I will in the hole. Is that clear? OK, and just for convenience in this talk I'm going to give myself a much bigger programming language. Now, here is the first definition of observational equivalence, OK? For every possible context in the language C, if I plug in e1 in the context and I plug in e2 in the context and I get the same result, whatever that means in a moment, I get the same result, then we'll decides the two terms are equivalent. If I plug in e1 and plug in e2 in every possible context, then the two terms are equivalent, OK? So it's essentially asking, is there any way in the code of telling these two things apart. So we ask the question of 0.999 versus 1 and etc. Question is. Is there any way in your he had code of telling them apart? It's a program oriented definition of a definition.
    Extremely pragmatic.
    
     AUDIENCE:  How do you tell it's C --
    
    >> ah, what does equality mean? As you can see, I've got a nice big red around that's what you were asking, right? OK, because so we've still ducked the question, in fact it's even worse. In a language like the lambda calculus, everything is like a lambda term, they're opaque, you can't look into them, what are you going to do with that. So Morris came up with an even more brilliant definition, OK? Morris said let's not talk about equality of things, because that's what we're trying to define. The more general definition is: If C of e1 halts, if and only if c of e2 halts.
    Ooh!  I know, I know, OK? For the rest of this talk, I need to say two things. One is I need a canonical way of talking about an infinite loop. We'll use omega. The other thing that's sort of relevant for what I'm going to do later is this little trick that people use in semantics, which is if you have a program with an error, you think of it as not terminating, OK? That's a technical thing. I don't want to go into it in detail. That's just relevant for one slide later in the talk.
    So we're going to reduce everything down to whether things terminate or not. And sometimes I'll also need to talk about which language, we're either in the language L or an extended language.
    So in that case I'll put an subscript of A means the did he have language A. Good? No, not good, what are you peopling nodding your heads about? This seems to imply 5 is equal to 6. Talk to your neighbors for a moment and see whether you should buy my definitions, I've thrown Ph.D.s to you, it doesn't mean you should buy it!  Talk to your neighbor. Go!
    
    (Audience chatter)
    
    In 5, 4, 3, 2, 1!  And we're back.
    We're back. You people are worse than a high school. OK. So you buy this? Is 5 equal to 6?
    >>
     AUDIENCE:  No.
    >> Why not? What context?
    >>
     AUDIENCE:  While.
    >> Ah, how about this context? So the context says, if hole equals 5, then I'm going to terminate it. We said it's for all contexts, remember? This is one of the contexts. That's how clever a definition it is, OK? Now, aha, oh, not so simple. What if your language doesn't have the ability to check for like equality to 5? Maybe it's got no equals for particular numbers, maybe it's just got 0?
    Unless maybe you have a context that looks like that, you subtract 5 and then check if it's 0. See that's the beauty of this definition, it's over all context in your language, OK? Now, and this is the part they never tell you in the papers, but this is what's so brilliant about this definition. Now, what if there is no way of telling these things apart, like there's no arithmetic, there's no 0? ? You know, there's no subtraction. Then what?
    5 = 6. There's no way in your language of telling them apart. Now, what distinction is there? You might be aha, I can probe into the hardware. Otherwise it's outside the scope of your language. Your compiler writer can merrily optimize away.
    OK, we're good? It's very subtle. We're going to work through this brilliant definition by Morris of this thing called observational equivalence. Checking for 0 is an observation, subtracting something and checking something, that's an observation, all of the observations. We're good? OK, now, good, let's go back to talking about expressiveness, OK so now I'm going to give you a definition of expressiveness, but I want to motivate it. So let's imagine we have a language where -- this is true of just about any language, I hope, 3 is the observational equivalent of 1 + 2, all right? Now, that's my language. Now, could you imagine adding some feature, F0 to this language, such that 3 is still equal to 1 + 2? What could you add to this language? There's so many things you can't even name one, right? You could add subtraction to the language and hopefully that leaves addition unchanged, right? So this is not hard to conceive of. Could you imagine adding some other feature F1 that leaves all of the things that were previously equal to still be equal? You can? Like, what could you imagine adding?
    Loops for instance, may leave all of the things that were equal still be equal, quite possibly. All right, could you imagine something like an F2 that would make 3 no longer be equal to 1 + 2, once you've added it to the language? You can? What could you imagine adding? Macros? What else? Floating point or -- any Python programs or overloading, right? I can just overwrite + to be something else. I could do it with macro, I could do it with overloading, lots of things, right? I could just change the meaning of "plus," right?
    So we have additional fee tourings. Does that make sense? That's where we're going. OK, very good. So here is the key theorem in this paper, OK? Suppose F can be written as a local macro. I'm not exactly defining local macro, your intuition should be a local macro that has relatively limited power. So like a syntax macro if that means something to you.
    So it just takes pieces and rearranges them like the do loop or the for loop that I showed you earlier. Just rearranges pieces.Oo so supposing I have two terms, for every term that is equal under L, OK, for every term that's equal under L, I'm guaranteed that it will still be equal when I add F to L.
    OK? For every term that's equal under L, it's guaranteed to still be equal when I add F to L. This is not completely obvious. This is like the core of the paper in some sense and it takes several pages to like work through to get to this point, but this is the key theorem. Whatever L had as equivalences, they're still there, they haven't been changed. F has not affected L in some material way. Does that make sense intuitively? OK, good. Now, the formal statement looks quite different. I'm just going to put it out just to show you that the paper is written in slightly different terminology. You will understand all of this based on this talk. You can go back and read this and you can translate these terms, it will make sense, I think.
    So that's the way the paper is written. But how do we show -- this is the thing, right? So we know that not expressive means you write a macro down and do some proof stuff, but whatever, just show that the macro doesn't do anything weird, OK? But how do we show something is expressive? Because, remember, this is our original quest. We started out by saying we have a way of showing expressiveness using touring completeness versus noncompleteness, the Chomsky hierarchy, I had all of these ways and then when we got into the Turing-complete world, we could no longer express our views on expressiveness, because everything was equal. So now we want a way -- we've created all this machinery to give ourselves a way to still show that things are expressive. That means not everything is complete cannily equal, right? So how do we show that * something is expressive. If we read or the theorem essentially backwards, here' the plan. We start with two terms:
    E1 and e2 such that they're equal. Now, I have an extension F my new feature, if we can find a context by the extension, such that e1 and e2 are no longer equal, right, that tells us that F has added power. If somehow F has messed around with L, right? It's changed L in some material way, things that used to be equal, compiler rewrites that a compiler writer could perform, they could no longer perform and if you think this is a theoretical question, go back to a real compile writer. Every time Rust adds a new feature, Racket adds a new feature, Python adds a new feature, this is what the compiler writers have to do. They have to ask what have been added before that have been invalidated or is it the case that this is a truly orthogonal addition? Very practical question.
    So good so far?
    So here's our game plan. OK? We have to find terms that were equal, we then have to find a context that is going to invalidate their equality, right?
    OK, and if we can show that, then it turns out by that theorem, there can not be a local macro for it, OK? But more to the point we've said something really powerful about expressions.
    So I'm going to do this on three language features, OK? First take a language without exceptions and add a halt feature to it. So halt is basically exit. You give it a thing and it stops the program, it doesn't continue execution, OK.
    So reminder: We need two terms: OK, e1 and e2, and then we need a context in the extended language, right?
    Two terms, e1, e2, context is extended language. So if we -- if this were a multi-day course, we could build all the extensions.
    So here is my first term. Let me help you with the notation. That is a function, it takes an argument, f, and it ignores it, what does it do? Can everyone do this? Yes, OK, so it takes an argument, ignores it and infinite loops, OK.
    All right, now, here is my term e2, I'm going to take an f, I'm going to apply f to 0 and then when I get something back I'm going to apply that to an infinite loop.
    I'm going to go into an infinite loop, OK? So it's pretty easy to see that these two terms are equivalent -- when I say equivalent, what do I mean? Equivalent by James Morris' definition, OK? Because no matter what f I give -- let's work through. No matter with a what f I give, it does this. Second expression: Let's say I give it an f that is not even a function. That's an error. That means it doesn't terminate. Or it is a function that -- well, that function goes off into an infinite loop, well, great, it's still an infinite loop. So they go into an infinite loop no matter what you apply them to. Good? So in all contexts, OK?
    So now I need to give you a context in my extended language.
    Right? Here's the context I'm going to give you and it's brutally short. The context is, I'm going to give halt as f.
    What happens in the first expression? What is e1 inside that context? Halt goes in as f, f is ignored, and the result?
    Infinite loops.
    Second expression: Halt goes in as f, and we say halt of 0 and the result of that is 0, OK?
    Therefore, I have found expressions that used to be equal that the act of adding halt makes not be equal. OK? Now, your first instinct might be to think, oh, OK, so he played some technical trick on us. That's very clever, Matthias did, really, not me. But is there an insight in here? Yes, there is an insight. The insight is the following: The insight is when I add halt to my language, I've added some real power to the programming language. The power I have added is the ability to ignore all the pending computations.
    Right? All sorts of computations were waiting to happen. I ignored all of them and bailed out, OK? So all that I'm doing with e1 and e2 is taking the intuition and translating it into code.
    Right?
    Because e1 is going to -- and I have to do it in a technical way because of my definition. E1 is not going to bail out. E2 is going to have the potential to bail out. In a language out halt, I can't exercise that potential. Once I add halt, I can exercise that potential. Do you see that? So really it starts with the intuition of what's the difference. What did I add because of this operator? And then you have to construct the idea, and then you have to do the mechanics to make sure, like, I put omegas in the right place.
    
    For those of you who know what call/cc is, call with continuous.
    In the second case, call/cc of f, the it will escape and so the same things works there, too.
    You see the game plan? Let me do a second language. Now, this one's gonna be fun.
    [laughter]
    OK, so the terms are going to be simple, but the context is going to be a little complicated. I'll walk through the context. All right, so here is my first term, it's a lambda that ignores its argument and applies f to 0, whatever f is. OK?
    E2 is going to look almost the same.
    I'll just apply f to 0 twice.
    In a pure language and if you are really picky, I can convert, we can expand e2 into a pure lambda term like there's an implicit begin or something, so don't worry. That's not interesting here.
    So basic whyly whether we apply f once or whether we apply f twice, it doesn't make any difference, right? It's a pure language. F is always going to have the same result.
    You see where I'm going? Yeah, you see exactly where I'm going. Because I'm going to construct my context now. And there's a lot of code, so let me just walk through the code for those of you who aren't familiar with how to read this. What I'm going to do is define this function f, it's going to take a parameter, it's going to return the result of that parameters but along the way it's going to change the thing that f is bound to, which is a procedure that is a diverging function, an infinite loop, OK? So when I apply this context to e1, what happens is I -- I basically -- I'm going to send 0 in, right? So 0 is going to go into the underscore position and get ignored. It's going to change f and return 0, and the computation terminates, right? In the second case it's changed f, but when I come back in, I changed f, so when I apply f again I'm going to diverge.
    The insight is, what does state do? State gives us the power to count. State gives us the power to count, right? Sometimes, as a functional programmer, sometimes I really, really want my programs to not -- to be like independent of time. And sometimes I very much want my programs to be dependent on time or dependent on the virtualization of time in terms of events that have happened. I want both things, and state gives us that. But what this is saying is, if you had programs that you had considered equivalent previously, now they might no longer be equivalent, because you added this feature, so you had to make sure that you added in a way that is reasonable for what you want to achieve, OK?
    And I forgot to show you this, but you know that already.
    OK, good, let me show you just one more example. There's a few more in the paper. The paper does some interesting distinctions of call by need, call by value but I'm not going to go into that. Let's say we have a language that has just a boolean value if. We're going to add a little truthy falsie if to it. So we'll do a Lispy if, if you're a true scripting language programmer, you know that the correct way is by a very complicated table with about 17 rules that are completely obvious to every programmer, except they're different in Ruby and JavaScript and everything else. OK, I don't have any opinions on this matter.
    OK, so here is my term. My term is going to be really complicated. I will explain this term to you, OK? I actually have two terms, remember? E1 and e2. There's e1. Can you tell there's a 1 that's a different color up there? OK, e2 is going to be the term but it's going to have an omega in that place and you can tell, aha!  Something tricky is going on there, right? OK, let me walk through this term for you, OK? So what are the possibilities? P could be not a procedure. If p is not a procedure. Then error, right? We can't apply a non-procedure, so is there any difference between e1 and e2? No, because the first thing -- they don't terminate, error. OK? But they have the same behavior.
    Another possibility is p actually applies its argument. If it applies its argument that's going to diverge, right? Which again they have the same behavior. First I have to convince you that e1 and e2 are the same, OK so that's what I'm doing.
    So third possibility is p takes its argument and feeds it an addition or something like that. That's an error.
    Fourth possibility: P puts its argument in a boolean if position, is that a boolean? No, that's a function.
    So the fifth possibility is actually the very interesting one, which is that p ignores its argument.
    If p ignores its argument, it must be a constant function. If it's a constant function, let's say it always picks false, then we're going to go to the omega case in both cases, if it's only picks true, we're going to go into the nested Bif and that's going to go into the 0 position and so we're going to go into the 0 position in both cases, so the key thing is this very cleverly constructed term, we never get to the orange term. It's dead code.
    OK?
    It's dead code in a language of boolean ifs, but now when I add my Lispy if.
    So now what has happened is, if I apply this to e1, what happens? Well, e1 is the lambda is a true -- so it's going to basically -- in both cases, the lambda is a true value, so it goes into the nested Bif, at that point, the false is a false value, so it goes into the else, so in p1 it's going to go into 1, in p2, it's going to go omega, and that is exactly the distinction that I needed to show. Termination versus nontermination, OK? What's the insight here? The insight is a truthy/falsy if allows us to perform more valuations than a boolean value if does.
    So that's my short tour. Now, in a pure language, you can add state by doing store-passing style, but that's a global transformation. You can add control operators to continuation-passing style. That's a global transformation. What this paper tells us is maybe you have a different global transformation, but you cannot do it as a purely local transformation, right? That is one of the consequences of this paper. Right? And furthermore, more profoundly, they really do add expressive power to the language.
    So let me wrap up now. First what did we learn? A really awesome, cool definition of equality. It's used all over the literature. Second, really need definition of expressiveness, we've gotten ourselves out of the Turing tar pit, we can now make distinctions inside the space of Turing completeness with mathematical truth not just a matter of opinion, OK?
    And finally I've shown you some proof sketches. What else is in the paper? There's a lot more in this paper. It's written as a sort of theoretical paper, pretty theoretical paper, so it's admittedly a little bit of hard going, OK? There's actually multiple notion of expressiveness, there's expression and local expressiveness, there's a proof of that theorem which is kind of not trivial. There's a relationship to logic and other formalizations of expressiveness.
    Now, as language designers, there's a lot for us in here. Desugaring macros are in in all of our languages nowadays. Everybody seems to be adding them. They're really unique. They come with a lots of powers. If they allow us to increase expressiveness, that's a thing we might want to think about doing with care, OK? The last thing I want to say is: There is a real benefit to having expressive features. I hope what this talk taught you is expressive features are a little bit bad and you have to approach them with caution. But on the other hand they also have benefits. They avoid these non-local global transformations. Callbackhelp.js is a website in fact!
    It gives you greater modularity and if you don't have it, people have to follow patterns, they can misuse them, they can get them wrong, it's also harder to tell what they mean. That's the end of the sermon part of the talk. I'm going to leave you with two homeworks, right? Homework No. 1. Anyone here know JavaScript in OK, let's see how well you know JavaScript. You know JavaScript has a feature called width. OK. Is width expressive? If you need a way to start, if you want to work on this homework, if you need a semantics for JavaScript, we wrote down a very simple clean simple semantics that's tested against reality and this paper gives a semantics for width by a compilation. The question is, is that possible or can you prove that it's impossible? OK, second homework problem. Anyone here program in Python? OK, good you're willing to admit it even though you know there's a homework coming. You know generators in Python? OK, are generators expressive? Now, you would think in fact it's a very careful design in Python to do generator basically through local CPS. Turns out that kind of breaks and if you want to know more about it we have a paper about semantics in Python. Because Python screws up scope, everything in the language suffers from the screwed-up scope. I'll leave you with one last thing. I asked Matthias, he ended up being my Ph.D. advisor because of this paper and I asked him for a photograph from back in the era, I showed you one. Here's the other one, we can't date the conference exactly but it was around 1990, it may even have been Matthias delivering a talk for this talk. It's that or it's a scene from Fritz LanG's Metropolis.
    I'll be happy to take your questions.
    [applause]
    
    Yes, I'll repeat the question. Yeah.
     AUDIENCE:  It seems like the whole thing is founded on theoretical concerns. What about if you could -- I mean you say it is -- what if something is frank infinite loop. You know what I'm saying?
    >> So the question is it seems to be founded on theoretical concerns and based on infinite loops, what if we wanted something that was maybe less than an infinite loop. First of all, I think I failed as a speaker because I think I tried numerous times to explain why as a compile writer is this of concern to you. So it's not theoretical concerns, every compile writer has be concerned with this.
    There's nothing that prevents you from taking that intermediate definition of observational equivalence, where I said are these two values equal using the equal sign, right? You might be perfectly happy saying, well, I have base values in my language, numbers and booleans and strings and stuff, ...
    You can reconstruct all of this without any of the infinite loops. Does that answer your question? Very good. Thank you. Other questions?
     AUDIENCE:  [inaudible] ah, I was hoping for this. So you defined equivalence in terms of not i, but this haltings, we've heard this halting thing before, there's some problem associated with it, I'm trying to remember what it's called. So yes, I did not give you an algorithm for figuring out equivalences. Ah!  The proofs we're doing by hand. You can do them by hand. Through an automated proof system or whatever but I'm not giving you an algorithm for determining these, you're still going to have to do these proofs through some algorithm that requires human insight, right? Ah, that means there might be things that are provable. If in fact if you carefully read that theorem statement. The second part is not about that but a related thing. There might be distinctions, there are distinctions can't tell, there are some we can tell, but that's not about the halting part. It's really about equality. The halting is just an artifact of the mechanical setup.
    >>
     AUDIENCE:  So this seems to be an extremely austere definition of expressiveness.
    >> Yes.
    >> Most of the:
     [inaudible]
     Syntactic sugar, which makes statements more -- pragmatically, can we use these methodologies to help us in those --
    >> Great question. So the question is basically we spend most of our time having debates about the human-facing sides of it, right, syntactic aspects of it, and this is a very austere, if you wish, but it's mathematical. As somebody who also cares very much and do some research on human factors in programming languages, I think we're remiss if we do one and not the other, right? We end up splitting into two camps. The theory people who do theory and the human people who do human factors and often these people have no idea what the other is. I think we need a balance between the two. I mean it's easy to say, but we need a balance where we can talk more about what it means to make something that's more expressive for a human but do we realize that in the process of adding that, we might have made things unexpressive or unintuitive for them. That's the part of the debate we never have. I can add this feature, but if the process if I've broken existing equivalence, that means somebody might look at it and -- I mean whop doesn't expect that you can replace 1 + 2 with 3? Right? So you could say, oh, it's a convenience to give somebody overloading, but did you also ask them, are you perfectly OK with 1 + 2 not being equal to 3?
    Because you can't anymore!  You have to unexpand all of those, right? So that's the way you link the formal with the human. Right? Because the formal is giving you a guide as to things that might have changed that you may not have wanted and you need to make sure those are OK changes for your community of users. Hand back over there.
    Oh, last one, sorry.
    [inaudible]
    
    >> Great question: So the question is about this undefinedness, right? So I basically said programs with errors don't terminate, right? And in fact, Matthias is a particularly good person to ask about that, because if I can channel Matthias for a moment, he'll tell you that's a terrible error, because people make distinctions all the time based on erroneous behavior. In fact, any practical language will tell you there are multiple exceptions not just stuff happened, OK? And we can make observations based on that. I can send in one kind of thing and get one sort of exception, send in another kind of thing and get another kind of exception, so really a more honest kind of programming language expressiveness would take that into account. This paper was written at a time when Matthias was starting to express the difference but this work was in an older tradition where theoreticians found it convenient to say, eh, when I can't evaluate, we'll just say the machine got stuck, okay, and there are stuck states, but stuck states are not terminating states, they're not quite the same as infinite loop states, but they're nonterminating states. It's not a satisfying definition from a programmer's Point of View and this paper expresses that. So you are right to be unhappy about that, I share your unhappiness, and I can tell you so does the author. On that note, thank you.
    [applause]
    
    
    Thanks, Shriram. Another ten minutes before he rushes out to the airport, so if you want to ask him more questions, he'll be right outside, I guess, or right out here to do that. We're going to have another talk in a couple of minutes here. We noticed people are kind of standing. We have the seats in the middle of these rows, try to get in there and use the seats up so people can sit down and we'll start in just a couple minutes.
    
