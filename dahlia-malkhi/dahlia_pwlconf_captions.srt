1
00:00:05,680 --> 00:00:07,440
DAHLIA MALKI: All right, good morning, everybody.

2
00:00:07,440 --> 00:00:08,440
AUDIENCE: Good morning!

3
00:00:08,440 --> 00:00:12,600
>> Oh, yeah, nothing like 200 geeks awake
at 9 in the morning.

4
00:00:12,600 --> 00:00:14,800
What a sight.

5
00:00:14,839 --> 00:00:19,119
So this talk can be one sentence.

6
00:00:19,119 --> 00:00:23,849
In every round, every node picks a random
target, exchanges some information, and waits

7
00:00:23,849 --> 00:00:25,400
for the next round.

8
00:00:25,400 --> 00:00:29,439
This is what I like about gossip algorithm,
they're simple, they're really literally one

9
00:00:29,439 --> 00:00:30,900
line.

10
00:00:30,900 --> 00:00:36,620
Because they're so simple, they're robust
to implement and simple and yet they're remarkably

11
00:00:36,620 --> 00:00:51,220
efficient and fault toll rant.

12
00:00:51,220 --> 00:00:59,900
Today I'm going to talk about three protocols
of this family, and go down to the basics.

13
00:00:59,900 --> 00:01:01,990
And we'll go right away.

14
00:01:01,990 --> 00:01:07,299
So the story actually begins with a company
that introduced and commercialized this technology.

15
00:01:07,299 --> 00:01:12,650
How many people recognize the technology and
the company?

16
00:01:12,650 --> 00:01:14,080
Not a single one.

17
00:01:14,080 --> 00:01:15,080
Laugh.

18
00:01:15,080 --> 00:01:16,080
OK.

19
00:01:16,080 --> 00:01:20,680
This is the company that also introduced the
first PC.

20
00:01:20,680 --> 00:01:27,940
The object-oriented programming languages,
the mouse, the ethernet, the first laser printer.

21
00:01:27,940 --> 00:01:32,700
How many people know what I am tea talking
about now?

22
00:01:32,700 --> 00:01:33,700
All right.

23
00:01:33,700 --> 00:01:36,590
So this is a xerox.

24
00:01:36,590 --> 00:01:44,070
It took it 20 years to take this first successful
paper to paper copy.

25
00:01:44,070 --> 00:01:47,030
This was the first successful copy of one
paper to another.

26
00:01:47,030 --> 00:01:54,440
It took it 20 years to commercialize this
and become, you know, a commercial product.

27
00:01:54,440 --> 00:01:59,010
And then they realized that the office of
tomorrow is going to be at least partially

28
00:01:59,010 --> 00:02:07,170
digital, so they founded Xerox Park and they
started this amazing group of researchers

29
00:02:07,170 --> 00:02:14,780
to help bring Xerox to the digital age, and
this is where this amazing group of scientists

30
00:02:14,780 --> 00:02:24,240
encountered the problem that led to the birth
of these gossip-based protocols.

31
00:02:24,240 --> 00:02:26,420
So what was the problem that they were grappling
with?

32
00:02:26,420 --> 00:02:31,959
So in the grapevine system, which was also
one of the first if not the first distributed

33
00:02:31,959 --> 00:02:41,640
network system, they needed to keep copies
of data consistent, and they came up with

34
00:02:41,640 --> 00:02:49,021
this randomized protocol for doing this, which
later received rigorous analysis, first in

35
00:02:49,021 --> 00:02:57,731
a POTC87 paper, and then further even more
strict and some variations of analysis in

36
00:02:57,731 --> 00:03:01,989
a wonderful FOX2000 paper.

37
00:03:01,989 --> 00:03:04,250
So what are we talking about?

38
00:03:04,250 --> 00:03:12,090
So the problem, the basic problem in grapevine
was initially to keep copies of mail synchronized

39
00:03:12,090 --> 00:03:13,470
throughout the cluster.

40
00:03:13,470 --> 00:03:18,000
So mail would arrive at one of the nodes and
from here, I'm going to talk about a network

41
00:03:18,000 --> 00:03:23,900
of nodes, and refer to all the players or
participants or processes or pieces simply

42
00:03:23,900 --> 00:03:25,130
as nodes.

43
00:03:25,130 --> 00:03:30,750
So mail arrives at one of the nodes, and the
obvious first solution that they came up with

44
00:03:30,750 --> 00:03:32,370
was direct mail.

45
00:03:32,370 --> 00:03:39,420
As soon as the mail arrives, the node multi-casts
the mail to all of the nodes in the network

46
00:03:39,420 --> 00:03:44,170
such that users can access their mail from
any node in this network.

47
00:03:44,170 --> 00:03:45,170
Problem?

48
00:03:45,170 --> 00:03:48,900
First of all, multi-cast is somewhat expensive.

49
00:03:48,900 --> 00:03:53,160
Networks did not necessarily support it, so
the node had to contact one at a time.

50
00:03:53,160 --> 00:03:59,150
Each one of the nodes in the network, which
was already getting very, very scalable at

51
00:03:59,150 --> 00:04:00,150
a time.

52
00:04:00,150 --> 00:04:02,680
We're talking about 8 to 16 nodes.

53
00:04:02,680 --> 00:04:04,180
That was a heavy burden.

54
00:04:04,180 --> 00:04:11,670
And it was difficult, because there were also
failures, so at the time when the mail arrived,

55
00:04:11,670 --> 00:04:16,200
and the node was trying to contact one of
the nodes, it may be down or there may be

56
00:04:16,200 --> 00:04:21,989
message omissions so it had to remember to
contact later, and then maybe when later the

57
00:04:21,989 --> 00:04:30,090
node that used to be down is up, now the origin
would then fail, and so they ran into a lot

58
00:04:30,090 --> 00:04:35,920
of difficulties of keeping this direct mail
method working.

59
00:04:35,920 --> 00:04:40,720
So their second attempt was what they called
anti-entropy.

60
00:04:40,720 --> 00:04:47,930
So anti- entropy worked by occasionally having
nodes contact one another and compare their

61
00:04:47,930 --> 00:04:54,610
database of mails, and later they used the
same thing for something like DNS, for network

62
00:04:54,610 --> 00:04:59,660
addresses directory, so they would just compare
their entire database and see what's missing

63
00:04:59,660 --> 00:05:02,210
and then send each other the missing information.

64
00:05:02,210 --> 00:05:08,280
So that actually worked, and converged, and
any information in the network would eventually

65
00:05:08,280 --> 00:05:10,280
reach everybody.

66
00:05:10,280 --> 00:05:18,560
So already there was some randomization here,
so by occasionally picking a random communication

67
00:05:18,560 --> 00:05:23,990
partner, every period of time, and synchronizing
with them, there was already this phenomenon

68
00:05:23,990 --> 00:05:30,030
that over time all necessary information got
everywhere.

69
00:05:30,030 --> 00:05:35,720
But it also fundamentally relied on synchronizing
databases, comparing them and sending what's

70
00:05:35,720 --> 00:05:41,530
missing, keeping information essentially forever,
even deletions had to be kept around for quite

71
00:05:41,530 --> 00:05:51,840
a long time in order for synchronization to
work.

72
00:05:51,840 --> 00:05:56,139
It was quite expensive and quite slow to operate.

73
00:05:56,139 --> 00:06:01,210
So finally this led to the first actual gossip
protocol, which from here on I will refer

74
00:06:01,210 --> 00:06:06,900
to as randomized gossip, and that was the
rumormongering protocol.

75
00:06:06,900 --> 00:06:14,070
So here the idea is to totally rely on gossip
to spread information, so mail or any kind

76
00:06:14,070 --> 00:06:19,740
of update more generally arrives at a node,
the node keeps it for a certain duration,

77
00:06:19,740 --> 00:06:25,570
during this duration, every once in a while
every period wakes up, sends a copy to a random

78
00:06:25,570 --> 00:06:31,139
partner and then after a duration, if you
believe that the gossip worked, it marks these

79
00:06:31,139 --> 00:06:36,770
information as no longer hot and stops gossiping
about it.

80
00:06:36,770 --> 00:06:38,980
All other nodes do the same thing.

81
00:06:38,980 --> 00:06:45,060
Every once in a while, wake up, send a copy
of their information, do that for a few rounds,

82
00:06:45,060 --> 00:06:50,130
exactly the duration that the gossip proceed
ducts that's needed, and then mark this information

83
00:06:50,130 --> 00:06:56,820
as OK, completely synchronized, gossip has
completed, and stop gossiping about it.

84
00:06:56,820 --> 00:07:04,199
So complete reliance on the gossip protocol
to disseminate the information throughout

85
00:07:04,199 --> 00:07:11,620
the network, completely, and reliably.

86
00:07:11,620 --> 00:07:16,050
So now let's move away from grapevine and
look at this more foundationally.

87
00:07:16,050 --> 00:07:22,290
I know it's early in the morning, but my hope
it to look at the foundations, look at the

88
00:07:22,290 --> 00:07:29,800
analysis of this without scaring you and to
actually make it more accessible, not less,

89
00:07:29,800 --> 00:07:33,539
if I can understand it, I think anybody can.

90
00:07:33,539 --> 00:07:39,720
So in order to do this, we do need to look
at, you know, the precise definitions and

91
00:07:39,720 --> 00:07:43,979
assumptions made in this algorithm.

92
00:07:43,979 --> 00:07:45,530
It's a really simple, one-line algorithm.

93
00:07:45,530 --> 00:07:53,560
So all we need is to say the following: We
assume -- or we ask the protocol to work in

94
00:07:53,560 --> 00:08:02,160
logically synchronous rounds.

95
00:08:02,160 --> 00:08:06,340
We're not going to mix and match messages
from different rounds.

96
00:08:06,340 --> 00:08:12,930
So logically all the nodes in the network
go through rounds one at a time where they

97
00:08:12,930 --> 00:08:16,250
do their operations, process and continue
to the next round.

98
00:08:16,250 --> 00:08:23,599
So logically it's a wave of actions one by
one.

99
00:08:23,599 --> 00:08:26,360
So that's what we mean when we say by synchronous
rounds.

100
00:08:26,360 --> 00:08:30,800
We're going to implement it this way and we
also need this for the analysis.

101
00:08:30,800 --> 00:08:37,479
As we said, the algorithm is just one line.

102
00:08:37,479 --> 00:08:42,529
In each one of these rounds, a node picks
a random target, and exchanges information

103
00:08:42,529 --> 00:08:43,529
with it.

104
00:08:43,529 --> 00:08:49,179
For this to actually be meaningful, for this
to be well defined, implicitly we assume that

105
00:08:49,179 --> 00:08:55,519
every node knows all the other nodes in the
network and from here, we're going to use

106
00:08:55,519 --> 00:09:00,089
n to denote the obligatory number of nodes
in the network.

107
00:09:00,089 --> 00:09:06,470
But implicitly notice that the assumption
here is that there's full information and

108
00:09:06,470 --> 00:09:13,319
full connectivity in this net work, so every
node can pick another node perfectly uniformly

109
00:09:13,319 --> 00:09:14,500
at random.

110
00:09:14,500 --> 00:09:20,850
This will not work if there's any kind of
skew or information is lacking.

111
00:09:20,850 --> 00:09:22,899
And this assumption does not hold.

112
00:09:22,899 --> 00:09:30,290
And the assumption about the network is that
every node can in fact form an interaction

113
00:09:30,290 --> 00:09:35,190
with every other node in the network.

114
00:09:35,190 --> 00:09:39,369
So in this framework, there are many, many
protocols and many variants.

115
00:09:39,369 --> 00:09:41,079
I'm going to look at three today.

116
00:09:41,079 --> 00:09:46,970
The first one is the analysis of this rumor-mongering
that I just talked about, just a simple synthesis

117
00:09:46,970 --> 00:09:50,459
of information that.

118
00:09:50,459 --> 00:09:56,670
This was the system that was developed at
Xerox PARC.

119
00:09:56,670 --> 00:10:05,319
The second is method detailed at Cornell University.

120
00:10:05,319 --> 00:10:14,439
And the third one with will be network discovery
where the information we send is used to build

121
00:10:14,439 --> 00:10:17,199
the network itself.

122
00:10:17,199 --> 00:10:24,850
And this is a method and work that was developed
by the Akamai engineers when they faced scalable

123
00:10:24,850 --> 00:10:25,850
networking.

124
00:10:25,850 --> 00:10:31,500
OK, so let me start with a simple information
dissemination, rumor-mongering.

125
00:10:31,500 --> 00:10:37,239
So we'll do that first by demonstration, so
here we have a network, it's a full network,

126
00:10:37,239 --> 00:10:42,189
everybody is connected to everybody else.

127
00:10:42,189 --> 00:10:48,309
We will call the node that first holds a copy
of the message informed in the literature

128
00:10:48,309 --> 00:10:52,889
sometimes it's infected or you know, many
other terms.

129
00:10:52,889 --> 00:10:59,469
Here I will call every node that holds a copy
of the information that we want to spread informed

130
00:10:59,980 --> 00:11:05,179
All right, so we have the first node that's
informed and what's used to spread the message

131
00:11:05,179 --> 00:11:07,360
using randomized gossip.

132
00:11:07,360 --> 00:11:12,160
So first for clarity of the slides get rid
of the network and we're going to assume this

133
00:11:12,160 --> 00:11:14,049
implicitly from now on.

134
00:11:14,049 --> 00:11:19,619
It's going to pick a random parter and send
information to it.

135
00:11:19,619 --> 00:11:24,360
So here I want to give you a point of view
which you won't actually find in the literature,

136
00:11:24,360 --> 00:11:29,889
and it's not actually really precise or correct,
but just mind intuition the way I think about

137
00:11:29,889 --> 00:11:30,889
it.

138
00:11:30,889 --> 00:11:36,899
So the way I think about it is the original
node had the responsibility to send a copy

139
00:11:36,899 --> 00:11:41,449
of the original gossip message to n recipients.

140
00:11:41,449 --> 00:11:49,299
It's going to recruit help and say look, why
don't you be responsible for half of it and

141
00:11:49,299 --> 00:11:52,690
I'll still be responsible for half of it.

142
00:11:52,690 --> 00:11:59,579
OK, so now in the next round, we have another
node which is informed, and in the next round,

143
00:11:59,579 --> 00:12:03,100
they're both going to proceed autonomously
and concurrently.

144
00:12:03,100 --> 00:12:06,290
So now two nodes are actually gossiping and
they're each doing the same thing.

145
00:12:06,290 --> 00:12:10,839
They're each picking another node to help
them, not just to inform them but also to

146
00:12:10,839 --> 00:12:15,000
become active gossipers of the message.

147
00:12:15,000 --> 00:12:24,269
So it's as if they say in the next round,
OK, we had responsibility each for half of

148
00:12:24,269 --> 00:12:29,199
the dissemination, and now each one of us
is going to choose a partner and ask for help

149
00:12:29,199 --> 00:12:30,369
in a quarter.

150
00:12:30,369 --> 00:12:34,310
So now we have four nodes, each one of them
responsible for further spreading the message

151
00:12:34,310 --> 00:12:39,439
to a quarter.

152
00:12:39,439 --> 00:12:42,220
And this continues in the next round, it's
n over 8.

153
00:12:42,220 --> 00:12:52,059
Now, I only have 8 nodes on this slide, so
in principle, we should have completed, if

154
00:12:52,059 --> 00:12:58,439
this was precise, but we know that actually
what happens is that there's certain inefficiency.

155
00:12:58,439 --> 00:13:05,119
Nodes will collide and send the same information
to the same target, so actually we didn't

156
00:13:05,119 --> 00:13:09,319
finish and another round is needed in this
example to finish.

157
00:13:09,319 --> 00:13:15,220
Let me actually scroll back and look at the
process again, a little bit slowly.

158
00:13:15,220 --> 00:13:22,959
So what really happens is that first, most
of the nodes that are chosen as gossip partners

159
00:13:22,959 --> 00:13:24,269
are not informed.

160
00:13:24,269 --> 00:13:31,519
So with very good efficiency, every gossip
message reaches an uninformed node, and turns

161
00:13:31,519 --> 00:13:34,859
it into informed.

162
00:13:34,859 --> 00:13:40,529
And this happens so long as about half of
the network is still uninformed.

163
00:13:40,529 --> 00:13:45,579
We have the probability of at least a half
of reaching an uninformed nodes, so really

164
00:13:45,579 --> 00:13:49,449
every round is very effective.

165
00:13:49,449 --> 00:13:55,480
It grows the number of informed nodes by a
constant factor, almost doubles the number

166
00:13:55,480 --> 00:13:56,480
of informed nodes.

167
00:13:56,480 --> 00:14:03,889
At some point the network starts becoming
mostly informed, and here we start wasting

168
00:14:03,889 --> 00:14:10,920
communication just to reach the few unlucky
nodes that are still uninformed.

169
00:14:10,920 --> 00:14:16,589
So here there's only one uninformed node and
everybody is trying to target it, hopefully

170
00:14:16,589 --> 00:14:24,259
within a few rounds somebody will actually
pick this unlucky node and complete the process.

171
00:14:24,259 --> 00:14:30,519
So this intuition is in fact what we can use
for formal analysis.

172
00:14:30,519 --> 00:14:37,149
So to look at the formal analysis, we're looking
at the number of aspects of the process.

173
00:14:37,149 --> 00:14:43,879
So first of all, again, we have n nodes and
we're going to look at the gossip process

174
00:14:43,879 --> 00:14:49,209
and its complexity, focusing on gossip of
one message only.

175
00:14:49,209 --> 00:14:54,459
There may be a lot of messages and in fact
in most systems, there may be multiple messages,

176
00:14:54,459 --> 00:14:59,720
simultaneously being gossiped and we're going
to piggyback on the same connections and potentially

177
00:14:59,720 --> 00:15:04,189
transfer many messages but for the analysis
it's enough to follow what's happening for

178
00:15:04,189 --> 00:15:05,990
one message only.

179
00:15:05,990 --> 00:15:14,730
And then it turns out that the basic framework
that I gave still there's a lot of flexibility.

180
00:15:14,730 --> 00:15:21,049
So the framework says in every round a node
picks a random partner for interaction, but

181
00:15:21,049 --> 00:15:27,489
it doesn't really say then how do they exchange
information, and in fact, it turns out that

182
00:15:27,489 --> 00:15:33,029
very different behavior occurs if the information
is pushed to the partner, if the information

183
00:15:33,029 --> 00:15:36,470
is pulled from it, or if it's pushed and pulled.

184
00:15:36,470 --> 00:15:40,720
And I think that that understanding it gives
a lot of insight on this process and I'm going

185
00:15:40,720 --> 00:15:42,519
to do this in the next few minutes.

186
00:15:42,519 --> 00:15:45,259
It's going to be a little bit of math.

187
00:15:45,259 --> 00:15:49,230
If you really, really dread it, this is the
time to go on your Twitter and come back in

188
00:15:49,230 --> 00:15:50,799
about 20 minutes.

189
00:15:50,799 --> 00:15:56,029
So in about 10 minutes I'll get back to failure
detection or if you're really waiting for

190
00:15:56,029 --> 00:15:59,879
it this is the 10 minutes that you could take
a little bit of math but really just a little

191
00:15:59,879 --> 00:16:03,350
bit.

192
00:16:03,350 --> 00:16:11,420
I'll try to be precise and at the same time,
gloss over some details.

193
00:16:11,420 --> 00:16:14,439
So let's first look and say something obvious.

194
00:16:14,439 --> 00:16:23,879
It's sort of obvious that if at every round
every node has -- is allowed only one interaction,

195
00:16:23,879 --> 00:16:26,329
one connection with one other node.

196
00:16:26,329 --> 00:16:33,100
The best we could do is spread the message
in log n number of rounds.

197
00:16:33,100 --> 00:16:38,230
Let's look at the graph of all of connections
which are formed during this process.

198
00:16:38,230 --> 00:16:45,170
OK, this is a graph where each node has out
degree, has a logarithmic log n number of

199
00:16:45,170 --> 00:16:52,249
corrections that it chooses to other nodes
and it's well known in the theory of random

200
00:16:52,249 --> 00:16:57,910
graphs that this graph will have log n diameter,
with high probability in expectation and also

201
00:16:57,910 --> 00:16:59,709
with very high probability.

202
00:16:59,709 --> 00:17:04,319
So if the graph has log n diameter and we're
starting with a examination on one node, it

203
00:17:04,319 --> 00:17:11,439
will take log n even with the best structure
of algorithm to cross the graph.

204
00:17:11,439 --> 00:17:15,829
If you're looking at what I'm saying in the
slide it's not the same.

205
00:17:15,829 --> 00:17:18,519
This is saying the same thing, but actually
proving it.

206
00:17:18,519 --> 00:17:24,170
But if you just think of this as a random
graph with log n edges, you immediately see

207
00:17:24,170 --> 00:17:28,930
that it will take, you know, logarithmic number
of steps for the message to move from one

208
00:17:28,930 --> 00:17:32,730
end of the graph to another.

209
00:17:32,730 --> 00:17:36,509
OK, now let's look.

210
00:17:36,509 --> 00:17:37,619
So this is the lower bound.

211
00:17:37,619 --> 00:17:40,740
There's nothing you can do better with so
few connection.

212
00:17:40,740 --> 00:17:46,420
Let's look actually at an upper bound, so
how long does it take to actually complete.

213
00:17:46,420 --> 00:17:51,440
And we're going to split the analysis into
push and pull.

214
00:17:51,440 --> 00:17:53,230
We'll start with the push analysis.

215
00:17:53,230 --> 00:17:57,550
And we're going to split the push analysis
into two parts.

216
00:17:57,550 --> 00:18:05,139
The first part is when less than half of the
network is informed, so the message has reached,

217
00:18:05,139 --> 00:18:07,630
less than half of the network.

218
00:18:07,630 --> 00:18:15,250
What we can say then is that every push by
an informed node has a pretty good chance

219
00:18:15,250 --> 00:18:18,990
of succeeding, at least half.

220
00:18:18,990 --> 00:18:26,200
And in expectation, all together, the set
of informed nodes have an expected half, you

221
00:18:26,200 --> 00:18:30,450
know, is expected to grow by a factor of at
least half of them.

222
00:18:30,450 --> 00:18:35,650
So at least half of them actually get to uninformed
nodes.

223
00:18:35,650 --> 00:18:36,750
So this is an expectation.

224
00:18:36,750 --> 00:18:42,640
There are two things that we need to do in
order to move this into a high probability,

225
00:18:42,640 --> 00:18:44,519
high assurance result.

226
00:18:44,519 --> 00:18:48,380
And in this talk and in most of the papers
we will consider something that happens with

227
00:18:48,380 --> 00:18:54,789
probability at least 1n 1/n.

228
00:18:54,789 --> 00:19:00,529
We'll consider that small enough probability.

229
00:19:00,529 --> 00:19:06,409
It's really easy to get this to 1 over n squared
or any probability that you want.

230
00:19:06,409 --> 00:19:09,049
Any polynomial probability that you want.

231
00:19:09,049 --> 00:19:13,600
So in order to move this to high probability
behavior, we need to consider two things.

232
00:19:13,600 --> 00:19:20,389
The one is even if informed nodes get to uninformed
nodes there's some collision, so there's some

233
00:19:20,389 --> 00:19:22,990
loss of efficiency there.

234
00:19:22,990 --> 00:19:32,630
And secondly, you know, these -- even though
the selection of partners is completely independent,

235
00:19:32,630 --> 00:19:41,740
the actual sum of uninformed nodes that become
informed, that's not an independent sum.

236
00:19:41,740 --> 00:19:48,200
But the dependency is small enough, every
two nodes can affect each other by at most

237
00:19:48,200 --> 00:19:54,549
1 if they collide and the collisions are rare
enough that you can rigorously show that the

238
00:19:54,549 --> 00:19:59,450
actual progress of the process is very close
to the expectation.

239
00:19:59,450 --> 00:20:06,000
So our intuition and actual rigorous analysis
are completely perfectly aligned in this case.

240
00:20:06,000 --> 00:20:13,590
Until you know half of -- or any constant
fraction of the network are informed, every

241
00:20:13,590 --> 00:20:18,550
round increases the set of informed nodes
by a constant factor.

242
00:20:18,550 --> 00:20:21,620
It's not exactly double, but it's close to
it.

243
00:20:21,620 --> 00:20:28,159
I can definitely say that it's at least grows
by a third.

244
00:20:28,159 --> 00:20:29,779
So this is the first half of the process.

245
00:20:29,779 --> 00:20:35,820
The second half of the process is when already
a significant fraction of the network, let's

246
00:20:35,820 --> 00:20:37,889
say a half, are informed.

247
00:20:37,889 --> 00:20:39,440
What happens then?

248
00:20:39,440 --> 00:20:47,409
So this is the part where we are losing a
lot of inefficiency just to get to the last

249
00:20:47,409 --> 00:20:48,409
remaining nodes.

250
00:20:48,409 --> 00:20:54,269
And those of you who are familiar with coupon-collector
analysis, this is exactly what's going on.

251
00:20:54,269 --> 00:20:59,720
We're going to throw a lot, a lot of messages,
n log n messages just to make sure that every

252
00:20:59,720 --> 00:21:03,450
single note is not missed.

253
00:21:03,450 --> 00:21:08,460
And so now, in each round, at least half of
the network is informed, so in each round,

254
00:21:08,460 --> 00:21:20,940
we are in fact throwing a linear number-messages,
n/2 at least, and so if we looked at the probability

255
00:21:20,940 --> 00:21:25,759
of an uninformed node to actually receive
any one of these messages, there's a little

256
00:21:25,759 --> 00:21:27,300
formula there.

257
00:21:27,300 --> 00:21:28,880
It's really a trivial formula.

258
00:21:28,880 --> 00:21:33,419
If I'm an uninformed node, the probability
that somebody, you know, one other node chooses

259
00:21:33,419 --> 00:21:34,750
me, is pretty small.

260
00:21:34,750 --> 00:21:43,179
It's 1/n, the probability that I'm not chosen
by that one other player is 1-1/n, but the

261
00:21:43,179 --> 00:21:53,610
probability that all of them don't choose
me, that's 1-1/n raised to the power of the

262
00:21:53,610 --> 00:21:55,000
number of uninformed nodes.

263
00:21:55,000 --> 00:21:56,000
At least 1/2.

264
00:21:56,000 --> 00:22:03,509
And if you look at this formula it converts
very easily to e to the-1/2.

265
00:22:03,509 --> 00:22:12,769
So the actual number doesn't really matter
whether it's a third or one other square root

266
00:22:12,769 --> 00:22:14,900
of 3.

267
00:22:14,900 --> 00:22:24,640
It's a constant number, non-negligible one,
that if I'm uninformed in around 1/2 random

268
00:22:24,640 --> 00:22:28,450
messages are send, I will receive it.

269
00:22:28,450 --> 00:22:30,490
So that's the probability.

270
00:22:30,490 --> 00:22:36,049
In order for this to happen with high probability,
I can raise this to log n and after log n

271
00:22:36,049 --> 00:22:41,169
rounds, then with high probability, I will
not be missed and all of the nodes will not

272
00:22:41,169 --> 00:22:42,169
be missed.

273
00:22:42,169 --> 00:22:50,490
And this is again why I need the high probability
to be at least 1/n so that in all nodes this

274
00:22:50,490 --> 00:22:52,030
will actually happen.

275
00:22:52,030 --> 00:23:00,529
So a very simple analysis actually shows this
powerful result that says that this actually

276
00:23:00,529 --> 00:23:01,529
happens.

277
00:23:01,529 --> 00:23:11,690
This is a randomized protocol, but with very
good strict guarantees of convergence.

278
00:23:11,690 --> 00:23:14,769
So this was the push protocol.

279
00:23:14,769 --> 00:23:18,330
I think it's actually remarkably illuminating
to also look at the pull protocol.

280
00:23:18,330 --> 00:23:21,150
I'll do it very quickly.

281
00:23:21,150 --> 00:23:25,610
In the pull protocol I'm using the basic same
framework.

282
00:23:25,610 --> 00:23:29,769
Every node chooses a partner at random in
a round.

283
00:23:29,769 --> 00:23:37,360
But now whenever a node chooses another node
to interact with, it pulls information from

284
00:23:37,360 --> 00:23:38,360
it.

285
00:23:38,360 --> 00:23:40,620
Whatever it has, it pulls from it.

286
00:23:40,620 --> 00:23:46,340
What happens in this protocol is that a very,
very same analysis to what we just had says

287
00:23:46,340 --> 00:23:53,929
that the one, you know, when we start, the
one node that actually has the message will

288
00:23:53,929 --> 00:23:58,850
be selected by one other node with constant
probability, exactly the same probability

289
00:23:58,850 --> 00:24:02,559
as in the opposite direction.

290
00:24:02,559 --> 00:24:03,559
So that's good.

291
00:24:03,559 --> 00:24:08,320
So this will look a little bit like gossip,
so one node pulls from the informed node,

292
00:24:08,320 --> 00:24:12,200
looks a little bit like the informed node
pushes to one other node.

293
00:24:12,200 --> 00:24:18,270
Except that with non-negligible probability,
this will also not happen in the first round

294
00:24:18,270 --> 00:24:25,830
or the second round or ten rounds and in fact,
it's not unlikely at all that for logarithmic

295
00:24:25,830 --> 00:24:28,850
number of rounds, no pulls will be successful.

296
00:24:28,850 --> 00:24:35,080
Only log n rounds can I guarantee that even
a single pool succeeds, and the same thing

297
00:24:35,080 --> 00:24:39,749
happens if you know, one or two pulls succeed
and we have a small constant number of informed

298
00:24:39,749 --> 00:24:48,980
nodes, we can still, you know, not very unlikely
that we'll miss them or definitely not grow

299
00:24:48,980 --> 00:24:51,780
the set of informed nodes by a constant factor.

300
00:24:51,780 --> 00:24:59,470
So there's a long startup of the pull process
until we reach a logarithmic size of informed

301
00:24:59,470 --> 00:25:00,470
set.

302
00:25:00,470 --> 00:25:10,090
Once we cross that threshold, then the rest
of the first part of the process behaves exactly

303
00:25:10,090 --> 00:25:11,090
like push.

304
00:25:11,090 --> 00:25:17,960
So the set of informed nodes will increase
by a constant factor in every round.

305
00:25:17,960 --> 00:25:24,059
The second half of the pull process, once
a significant part of the network, half of

306
00:25:24,059 --> 00:25:32,159
the network is informed, that's actually considerably
different and remarkably, you know, insightful,

307
00:25:32,159 --> 00:25:34,509
to what goes on in the gossip process.

308
00:25:34,509 --> 00:25:41,919
So now we have, you know, some fraction, let's
say half of the network, which are informed.

309
00:25:41,919 --> 00:25:45,519
And the other half is uninformed.

310
00:25:45,519 --> 00:25:54,070
So let's say that we have some fraction which
are uninformed.

311
00:25:54,070 --> 00:25:59,330
I'll.

312
00:25:59,330 --> 00:26:07,370
You can immediately say that an uninformed
node stays uninformed with probability C.

313
00:26:07,370 --> 00:26:14,179
So we have C times n uninformed nodes and
uninformed nodes picks a node at random.

314
00:26:14,179 --> 00:26:16,270
It picks an uninformed node.

315
00:26:16,270 --> 00:26:19,330
Probability 1 picks an uninformed node.

316
00:26:19,330 --> 00:26:27,179
So the expected number of uninformed nodes
goes from CXn to C squared Xn, but this is

317
00:26:27,179 --> 00:26:34,820
very, very different from 2 times C. So now
we're squaring the fraction of uninformed

318
00:26:34,820 --> 00:26:36,309
nodes in every round.

319
00:26:36,309 --> 00:26:42,049
So if we start with half of n uninformed in
one round we go to a quarter.

320
00:26:42,049 --> 00:26:43,750
In the next round we grow to?

321
00:26:43,750 --> 00:26:44,850
AUDIENCE: 8.

322
00:26:44,850 --> 00:26:49,250
No, good, that's what I was ready for.

323
00:26:49,250 --> 00:26:55,190
So not to an eighth, but to 1/4 squared, which
is?

324
00:26:55,190 --> 00:26:57,419
16.

325
00:26:57,419 --> 00:26:58,679
>> Not to put you on the spot.

326
00:26:58,679 --> 00:27:02,650
This really takes a moment to stop and think.

327
00:27:02,650 --> 00:27:05,259
This is a really much much faster process.

328
00:27:05,259 --> 00:27:09,400
This is not an exponential process, this is
super-exponential, so again, very trivial

329
00:27:09,400 --> 00:27:12,389
math, nothing complicated, sorry.

330
00:27:12,389 --> 00:27:16,049
[laughter]
But what it means is that in the pull process

331
00:27:16,049 --> 00:27:22,620
now, the part of the gossip process kiss heavy,
which is really sending a lot of messages,

332
00:27:22,620 --> 00:27:28,350
converges much much more quickly and if you
do the math, it's log log n rounds and log

333
00:27:28,350 --> 00:27:33,820
log n rounds to this audience, to me, that's
as good as a constant.

334
00:27:33,820 --> 00:27:37,670
That is a really, really small number.

335
00:27:37,670 --> 00:27:44,740
So pull and push are very, very different,
and this led to a beautiful result in the

336
00:27:44,740 --> 00:27:52,570
2000 paper, by Karp et al., where they've
combined push and push, they say, well, pull

337
00:27:52,570 --> 00:28:00,539
has this long warmup, startup phase, but then
after it reaches a certain fraction of the

338
00:28:00,539 --> 00:28:05,720
network, it converges much much more quickly,
much more efficiently and with much fewer

339
00:28:05,720 --> 00:28:10,480
rounds, but not just rounds, messages.

340
00:28:10,480 --> 00:28:15,990
If we could only identify when to transition,
then we're good, and so they've developed

341
00:28:15,990 --> 00:28:23,059
a simple protocol that carries information
with it, and identifies when to switch over,

342
00:28:23,059 --> 00:28:29,470
and so then the first part of gossip, where
the first informed nodes sends to others,

343
00:28:29,470 --> 00:28:36,940
then two others send to four, and then all
of this initial phase we're only sending linear

344
00:28:36,940 --> 00:28:38,619
number of messages.

345
00:28:38,619 --> 00:28:42,779
And then in the second half, if we switch
to pull, we're sending almost linear.

346
00:28:42,779 --> 00:28:54,360
We're send N times log log n, which for all
practical purposes is almost linear.

347
00:28:54,360 --> 00:29:04,570
So to wrap up the first protocol in this family,
and really the one that started the interest

348
00:29:04,570 --> 00:29:12,400
in randomized gossip protocol, the basic rumor-mongering,
basic information dissemination by gossip

349
00:29:12,400 --> 00:29:21,070
protocol, we didn't talk at all about this,
but it's inherently fault tolerant.

350
00:29:21,070 --> 00:29:27,440
If we choose a random partner that's faulty
at any point in the protocol, it's remarkably

351
00:29:27,440 --> 00:29:29,120
resilient to that.

352
00:29:29,120 --> 00:29:30,149
It's very simple.

353
00:29:30,149 --> 00:29:34,940
We talked about it being one line.

354
00:29:34,940 --> 00:29:39,899
And when you understand the round and the
message complexity, you can see that first

355
00:29:39,899 --> 00:29:43,020
of all the round complexity is as optimal
as it can be.

356
00:29:43,020 --> 00:29:46,299
The message plexity, well, there is a cost.

357
00:29:46,299 --> 00:30:01,740
Naively, you -- so you say slightly more than
some deterministic multi-cast regime, but

358
00:30:01,740 --> 00:30:07,210
still, you main, you know, amazing simplicity
and fault tolerance.

359
00:30:07,210 --> 00:30:12,841
At the same time, I also emphasize that all
of this works, and we can analyze it in a

360
00:30:12,841 --> 00:30:17,580
full network with perfect knowledge of the
network.

361
00:30:17,580 --> 00:30:23,610
We don't know anything if any process has
only partial knowledge.

362
00:30:23,610 --> 00:30:27,830
Some selections, some random subset of the
network to talk to, you we don't know anything

363
00:30:27,830 --> 00:30:30,570
about the convergence of this protocol.

364
00:30:30,570 --> 00:30:36,169
Any questions before we move to, you know,
interesting use cases?

365
00:30:36,169 --> 00:30:37,429
Yes?

366
00:30:37,429 --> 00:30:53,309
AUDIENCE: Is it possible in the push protocol
to make sure a node doesn't push to the same

367
00:30:53,309 --> 00:30:54,309
node as --
>> No.

368
00:30:54,309 --> 00:30:59,509
>> Is there any way to guarantee that the
same node is not picked twice as a gossip

369
00:30:59,509 --> 00:31:04,440
target, either by the same node or even from
two?

370
00:31:04,440 --> 00:31:10,309
I mean, you can patch -- you can patch the
protocol, the basic framework did not preclude

371
00:31:10,309 --> 00:31:11,830
this and does not need this.

372
00:31:11,830 --> 00:31:15,700
So ... that didn't answer your question?

373
00:31:15,700 --> 00:31:16,830
I was talking the same node.

374
00:31:16,830 --> 00:31:22,080
The same node as pushing, it wouldn't push
the same node twice, would it?

375
00:31:22,080 --> 00:31:31,580
>> So you can definitely add to your algorithm
some, you know, simple test that removes this

376
00:31:31,580 --> 00:31:37,249
duplicity, it's not going to change the -- you
know, most of the complexity and the analysis

377
00:31:37,249 --> 00:31:42,529
remains exactly the same, but you could definitely
avoid this as really unnecessary.

378
00:31:42,529 --> 00:31:44,149
Not much efficiency is lost there.

379
00:31:44,149 --> 00:31:45,980
That's not a common event.

380
00:31:45,980 --> 00:31:47,619
AUDIENCE: OK.

381
00:31:47,619 --> 00:31:49,250
OK, yeah?

382
00:31:49,250 --> 00:31:52,520
>> (We have a microphone.)

383
00:31:52,520 --> 00:31:59,500
>> I was just curious, do you happen to have,
for example, a number for some, you know,

384
00:31:59,500 --> 00:32:04,140
in an example system where this has been deployed,
a number for what the probability actually

385
00:32:04,140 --> 00:32:11,289
is after the log n number of rounds that we
got very unlikely and didn't reach them all?

386
00:32:11,289 --> 00:32:14,340
Because it seems like we don't really know
if we did or not.

387
00:32:14,340 --> 00:32:17,320
So it seems interesting to know.

388
00:32:17,320 --> 00:32:21,659
>> So these numbers can be easily computed
and they are in the papers.

389
00:32:21,659 --> 00:32:24,070
I can't give you a number off the top of my
head.

390
00:32:24,070 --> 00:32:25,070
It's also not a number.

391
00:32:25,070 --> 00:32:26,070
It's a function of n.

392
00:32:26,070 --> 00:32:28,610
But I can tell you it goes very quickly.

393
00:32:28,610 --> 00:32:34,320
This is an exponential process, so it goes
down very, very quickly polynomially.

394
00:32:34,320 --> 00:32:40,580
If you do 2 log n rounds, the probability
is 1 over n squared.

395
00:32:40,580 --> 00:32:48,489
If you do 3, it will be 1/n cubed.

396
00:32:48,489 --> 00:32:57,539
So you can definitely pinpoint the probability
very easily, and very precisely.

397
00:32:57,539 --> 00:32:58,539
Yeah.

398
00:32:58,539 --> 00:33:03,919
Yeah, one more question here and then maybe
I'll continue and defer questions to the end.

399
00:33:03,919 --> 00:33:04,919
Yeah.

400
00:33:04,919 --> 00:33:10,739
AUDIENCE: Yeah, when you switch to the pull
protocol, how do the nodes that don't know

401
00:33:10,739 --> 00:33:13,929
that they need to know something, know that
it's time to pull?

402
00:33:13,929 --> 00:33:18,049
>> Yeah, so that's a perfect question and
I'll refer you to the paper, because -- uh,

403
00:33:18,049 --> 00:33:19,879
uh, I don't have time to go over it.

404
00:33:19,879 --> 00:33:21,260
It's not a trivial protocol.

405
00:33:21,260 --> 00:33:23,370
It's a really, really nice protocol.

406
00:33:23,370 --> 00:33:26,710
It's also not a complicated one.

407
00:33:26,710 --> 00:33:27,720
Really beautiful protocol.

408
00:33:27,720 --> 00:33:30,559
I recommend that you read the Fox paper.

409
00:33:30,559 --> 00:33:33,799
Now maybe it will look a little more accessible.

410
00:33:33,799 --> 00:33:38,980
Fox is a very scary conference in general,
but yeah.

411
00:33:38,980 --> 00:33:42,249
[laughter]
>> All right.

412
00:33:42,249 --> 00:33:50,330
So now let's switch gears and talk about one
of the most exciting use cases that I see

413
00:33:50,330 --> 00:33:55,210
in practice these days and that's failure
detection.

414
00:33:55,210 --> 00:34:01,379
>> So the work actually started by some early
paper on gossip-style failure detectors by

415
00:34:01,379 --> 00:34:10,080
... which simply used gossip to replace the
multi-cast of heartbeats in a network.

416
00:34:10,080 --> 00:34:16,700
That did not actually work too well and that
led to an improved attempt in the SWIM protocol.

417
00:34:16,700 --> 00:34:20,659
So the SWIM protocol is what I'm going to
talk about today.

418
00:34:20,659 --> 00:34:31,010
So in a nutshell, what SWIM does is two components
for maintaining failure detection in a scalable

419
00:34:31,010 --> 00:34:32,010
network.

420
00:34:32,010 --> 00:34:35,980
The first one is to say, we don't want everybody
to monitor everybody else.

421
00:34:35,980 --> 00:34:39,340
We don't want this, you know, quadratic behavior.

422
00:34:39,340 --> 00:34:47,730
We also don't want a centralized monitoring
service to have to monitor a very large and

423
00:34:47,730 --> 00:34:49,470
scalable network.

424
00:34:49,470 --> 00:34:54,369
So what we're going to do is we're going to
use this randomized regime, randomized framework,

425
00:34:54,369 --> 00:34:55,369
for monitoring.

426
00:34:55,369 --> 00:35:01,210
So in every round we're going to pick -- we're
going to let each node pick a node at random

427
00:35:01,210 --> 00:35:09,549
and test its health, send in a message and
wait for a reply.

428
00:35:09,549 --> 00:35:17,119
And because this somewhat ad hoc testing is
less stable, less predictable than actually

429
00:35:17,119 --> 00:35:25,760
having a heartbeat monitoring service implemented
over, you know, some reliable transport, like

430
00:35:25,760 --> 00:35:33,030
TCP/IP, because of this ad hoc wake up, send
a message, and wait for a reply, that has

431
00:35:33,030 --> 00:35:36,210
some stability concerns.

432
00:35:36,210 --> 00:35:45,160
The second idea in SWIM is that when a response
does not arrive, we elicit help from peers

433
00:35:45,160 --> 00:35:50,099
and ask them to also try to ping a node that's
not responsive.

434
00:35:50,099 --> 00:35:58,200
We only actually detect or suspect a failure
if all of the group of peers jointly do not

435
00:35:58,200 --> 00:36:00,180
receive a response from this node.

436
00:36:00,180 --> 00:36:01,309
So this is the first part.

437
00:36:01,309 --> 00:36:07,460
This is a randomized failure probing or health
probing.

438
00:36:07,460 --> 00:36:13,260
The second part is, what do we do when a problem
is detected or some change is detected?

439
00:36:13,260 --> 00:36:20,210
And here again, the idea is to use gossip
to disseminate only these changes alerts:

440
00:36:20,210 --> 00:36:32,119
Only these rare alerts and notifications,
we use gossip for them.

441
00:36:32,119 --> 00:36:39,890
So some of the nice ideas and properties that
are promised by this paradigm is, OK, we don't

442
00:36:39,890 --> 00:36:44,920
have a centralized monitoring service and
we don't have all to all, but because of the

443
00:36:44,920 --> 00:36:51,130
nice properties of gossip, we know that every
node has a pretty good chance, has a constant

444
00:36:51,130 --> 00:36:59,339
probability, of being selected by one other
node in a round.

445
00:36:59,339 --> 00:37:03,810
And also has a constant probability of actually
being selected.

446
00:37:03,810 --> 00:37:11,410
So if there is a failure with constant probability,
some node will detect it.

447
00:37:11,410 --> 00:37:16,599
So this is, you know, this is a completeness
property, and at the same time, because everything

448
00:37:16,599 --> 00:37:23,280
is built on top of the gossip framework, the
fundamental overhead appears to be constant

449
00:37:23,280 --> 00:37:27,869
in every round, essentially we're forming
a constant number of interactions, so no matter

450
00:37:27,869 --> 00:37:35,400
what we do, we send information, we expect
responses back, it fundamentally scales.

451
00:37:35,400 --> 00:37:46,070
>> And also, this idea that we separate the
monitoring and the actual dissemination of

452
00:37:46,070 --> 00:37:51,250
alerts, that's also a really nice property
and a really nice idea of this framework.

453
00:37:51,250 --> 00:37:54,329
Monitoring is something that you need to do
periodically and there's no way around it

454
00:37:54,329 --> 00:37:58,609
and we use randomization to drive the cost
low.

455
00:37:58,609 --> 00:38:03,190
Alerts and notification on the other hand,
they should be pretty rare.

456
00:38:03,190 --> 00:38:14,380
So we don't want to conflate these two, and
have to exchange information about the status

457
00:38:14,380 --> 00:38:16,390
of the network in each and every round.

458
00:38:16,390 --> 00:38:20,540
Only when actually something occur, then we
actually need to send alerts.

459
00:38:20,540 --> 00:38:27,790
So this is the basic idea in SWIM and let's
again see the protocol by example.

460
00:38:27,790 --> 00:38:31,720
So here's a case where we have a network,
you know, for the purposes of SWIM, I needed

461
00:38:31,720 --> 00:38:35,150
some more nodes to fill up the slide.

462
00:38:35,150 --> 00:38:39,500
We're not going to be able to do it with 8
nodes.

463
00:38:39,500 --> 00:38:42,890
And potentially one node, A, here is faulty.

464
00:38:42,890 --> 00:38:49,130
So with constant probability, some other node,
B, will actually choose it as a random partner

465
00:38:49,130 --> 00:38:53,160
and within a few rounds this will hopefully
happen.

466
00:38:53,160 --> 00:38:55,819
We'll send a message, we'll not get a response.

467
00:38:55,819 --> 00:39:00,040
So it will elicit help from peers so now there's
a peer group, they're all sending messages

468
00:39:00,040 --> 00:39:06,290
to A, all of these messages are not being
answered and then there will be a failure

469
00:39:06,290 --> 00:39:07,290
detection.

470
00:39:07,290 --> 00:39:12,790
And so this will lead to a normal gossip protocol.

471
00:39:12,790 --> 00:39:18,549
So now B wants to gossip to the network information
about the failure detection.

472
00:39:18,549 --> 00:39:21,290
So it's going to spread around this rumor,
A is faulty.

473
00:39:21,290 --> 00:39:24,270
And this will work.

474
00:39:24,270 --> 00:39:30,190
First there's only one source, second round
there are already two sources and we expect

475
00:39:30,190 --> 00:39:38,330
this exponential behavior where nodes are
spreading this information and very quickly

476
00:39:38,330 --> 00:39:41,470
within logarithmic number of rounds, the network
knows about it.

477
00:39:41,470 --> 00:39:43,530
OK, but wait, wait.

478
00:39:43,530 --> 00:39:48,750
Let's actually go back to the first time that
this gossip is sent.

479
00:39:48,750 --> 00:39:52,830
At this point, we already know from before
very, very few nodes know about this.

480
00:39:52,830 --> 00:39:58,210
At this point it was the origin and now it's
you know, selecting one more random partner,

481
00:39:58,210 --> 00:40:02,410
so the rest of the network doesn't know about
the failure and we're going to take our time

482
00:40:02,410 --> 00:40:03,960
and gossip about it slowly.

483
00:40:03,960 --> 00:40:10,640
But remember, meanwhile we're continuing,
you know, the normal operation of the SWIM

484
00:40:10,640 --> 00:40:11,640
protocol.

485
00:40:11,640 --> 00:40:17,730
So in the next round, with good probability,
another node will pick A as the target for

486
00:40:17,730 --> 00:40:22,260
monitoring, so this is the node C. Node C
pings to A, doesn't get a response, what's

487
00:40:22,260 --> 00:40:25,400
it going to do it's going to elicit help from
peers.

488
00:40:25,400 --> 00:40:35,819
So now there's a group of peers that are also
swarming A with probes and the same thing

489
00:40:35,819 --> 00:40:40,950
happens in the next round, so now two nodes
are gossiping A's failure to four nodes but

490
00:40:40,950 --> 00:40:46,190
still most of the network doesn't know about
it, so there's a node D now that also probes

491
00:40:46,190 --> 00:40:52,089
A and there's a group of peers that will come
around to help and this will actually continue

492
00:40:52,089 --> 00:40:58,230
as we know until about half of the network
already learns about the failure.

493
00:40:58,230 --> 00:41:07,980
Everybody in every round will continue probing
the same process A, and this will result in

494
00:41:07,980 --> 00:41:14,810
an inflation of probes all targeted at A because
we're now eliciting peers to help and so if

495
00:41:14,810 --> 00:41:21,170
there's a node that is having any kind of
transient network problems or any slowdown

496
00:41:21,170 --> 00:41:28,440
what will happen is that after once it's detected
to have a problem, actually the next rounds

497
00:41:28,440 --> 00:41:30,510
will only exacerbate it.

498
00:41:30,510 --> 00:41:36,559
It doesn't have any steady monitoring relationship
with any, you know, centralize had had monitoring

499
00:41:36,559 --> 00:41:43,820
in every round, again and again, you know,
a group of messages will actually target it.

500
00:41:43,820 --> 00:41:51,089
Also, if there is in fact a failure, if A
was faulty, it may take quite a while.

501
00:41:51,089 --> 00:41:57,010
So in a large network, you know, people are
talking about 1,000 or 10,000 nodes, order

502
00:41:57,010 --> 00:42:01,920
log n rounds to spread this information is
quite a while.

503
00:42:01,920 --> 00:42:08,260
So we saw that until actually information
about, you know, the failed response spreads

504
00:42:08,260 --> 00:42:11,859
in the network, that could take quite a long
time, and remember, we don't want to, you

505
00:42:11,859 --> 00:42:17,230
know, this is a failure detection, we don't
want to send these probes too frequently,

506
00:42:17,230 --> 00:42:23,349
so the gap, the period between rounds is pretty
sizable.

507
00:42:23,349 --> 00:42:31,140
So it takes quite a long time for this information
to actually spread.

508
00:42:31,140 --> 00:42:36,760
And during this time, as we saw, all of the
probes will continue.

509
00:42:36,760 --> 00:42:41,920
So one might ask, I don't know, and I invite
to discussion and I'll be happy to hear some

510
00:42:41,920 --> 00:42:46,250
of the experiences you have, but one might
ask could some of the alternatives actually

511
00:42:46,250 --> 00:42:47,250
help here.

512
00:42:47,250 --> 00:42:53,450
So some of the alternatives is to actually
leverage and use the transport protocol, you

513
00:42:53,450 --> 00:43:01,360
know, strong properties, whether it's TCP/IP
or something else.

514
00:43:01,360 --> 00:43:13,460
Whether it's a ring or some other hierarchical
structure and perhaps even have a heartbeat

515
00:43:13,460 --> 00:43:18,859
monitoring relationship when a failure is
detected, then it's forced on the other side,

516
00:43:18,859 --> 00:43:23,560
who knows, that might actually get over some
of these difficulties.

517
00:43:23,560 --> 00:43:24,869
But we're not even done.

518
00:43:24,869 --> 00:43:32,369
Let's continue looking at the SWIM process,
and now let's look at a slightly different

519
00:43:32,369 --> 00:43:33,369
scenario.

520
00:43:33,369 --> 00:43:36,520
So here, A was not actually faulty.

521
00:43:36,520 --> 00:43:42,780
So either we missed, you know, some response
from it, or maybe even A was the one that

522
00:43:42,780 --> 00:43:43,780
was faulty.

523
00:43:43,780 --> 00:43:50,930
Maybe it slept for a while, came back and
missed all of the responses that A sent it

524
00:43:50,930 --> 00:43:55,220
and also the peers that it recorded sent it.

525
00:43:55,220 --> 00:44:07,260
So there's this faulty notification which
is, which we start to gossip, and immediately

526
00:44:07,260 --> 00:44:12,510
another node, you know, in the next round
probes A and actually discovers that A is

527
00:44:12,510 --> 00:44:13,510
healthy.

528
00:44:13,510 --> 00:44:15,460
So this is the green probing.

529
00:44:15,460 --> 00:44:19,770
But it's not going to do anything about it,
because nobody reported that A is faulty yet.

530
00:44:19,770 --> 00:44:22,430
Gossip takes a long time to actually propagate.

531
00:44:22,430 --> 00:44:28,039
So this could happen to C and can happen to
D and in fact again, we know that up until

532
00:44:28,039 --> 00:44:33,940
almost the end of the gossip process, most
of the network doesn't know about it.

533
00:44:33,940 --> 00:44:38,799
Only after a logarithmic number of rounds,
when we reach let's say half of the network

534
00:44:38,799 --> 00:44:44,470
and half of them know that A is faulty, only
then do we expect some node to emerge that

535
00:44:44,470 --> 00:44:52,740
both heard that, you for example A is being
suspected, and goes and probes A in that round

536
00:44:52,740 --> 00:44:58,319
as the random partner and sees that oh, no,
A is alive.

537
00:44:58,319 --> 00:45:03,609
So here we're starting to see that additional
enhancements to the protocol were needed,

538
00:45:03,609 --> 00:45:12,210
so SWIM introduced this model that it's just
a suspicion, everybody holds onto it for a

539
00:45:12,210 --> 00:45:17,420
while and don't really remove the node from
the membership and see whether there's any

540
00:45:17,420 --> 00:45:19,289
conflicting information.

541
00:45:19,289 --> 00:45:23,240
If anybody actually probes the node and finds
that it's healthy it's going to start a conflicting

542
00:45:23,240 --> 00:45:24,240
rumor.

543
00:45:24,240 --> 00:45:29,310
So now we have one rumor about the failure
and another conflicting rumor saying the node

544
00:45:29,310 --> 00:45:30,849
is alive.

545
00:45:30,849 --> 00:45:35,670
And we know that rumors are completely randomized.

546
00:45:35,670 --> 00:45:39,640
Some of them hear about the health of the
node first before they here about the suspicion

547
00:45:39,640 --> 00:45:47,049
and all of them are around and all of this
is going on for a pretty prolonged period

548
00:45:47,049 --> 00:45:53,500
of time because we're talking about a logarithmic
process where each probing period is itself

549
00:45:53,500 --> 00:45:55,839
non-negligible.

550
00:45:55,839 --> 00:46:09,400
So let's start a confirmation that's again
a third rumor.

551
00:46:09,400 --> 00:46:10,569
Now I'm going to confirm this.

552
00:46:10,569 --> 00:46:16,510
But now you need to get the rest of the network
to converge.

553
00:46:16,510 --> 00:46:22,920
So here's a third rumor that confirms the
suspicion.

554
00:46:22,920 --> 00:46:31,450
So this works great in the case where, you
know, there was a failed suspicion, you know,

555
00:46:31,450 --> 00:46:38,770
a false suspicion by B, so B was out for a
while, suspected A, tried to spread a rumor

556
00:46:38,770 --> 00:46:43,760
that A was faulty, and then immediately everybody
corrected it.

557
00:46:43,760 --> 00:46:45,500
This could work great.

558
00:46:45,500 --> 00:46:52,740
Except that wait, what if A really was faulty,
but the last message from A actually did reach

559
00:46:52,740 --> 00:46:53,740
C?

560
00:46:53,740 --> 00:47:01,130
So C has heard that there's a suspicion about
A and tried to probe it, coincidentally in

561
00:47:01,130 --> 00:47:08,849
that round and was actually able to get some
responses due to some timing and ordering

562
00:47:08,849 --> 00:47:09,849
problem.

563
00:47:09,849 --> 00:47:16,770
Well, what happens now is that everybody in
proceeding rounds will again and again probe

564
00:47:16,770 --> 00:47:23,730
A, and this could be C and D and E, and you
know, for logarithmic number of rounds.

565
00:47:23,730 --> 00:47:29,839
Everybody will probe A, will find out that
it's faulty, will reinforce the gossip that

566
00:47:29,839 --> 00:47:37,079
A is faulty, but that there was this one message,
one node that received the last response from

567
00:47:37,079 --> 00:47:41,440
A saying no, A is alive, and it's going to
supersede all of them.

568
00:47:41,440 --> 00:47:46,520
OK because this is gossip, everything arrives
out of order.

569
00:47:46,520 --> 00:47:54,579
So in summary, if you look at some of the
enhancements that needed to make SWIM operate,

570
00:47:54,579 --> 00:47:57,039
there are quite a few of them.

571
00:47:57,039 --> 00:48:05,000
So we talked about the basic difficulty of
asynchronously probing, we don't actually

572
00:48:05,000 --> 00:48:09,859
have full trust in this probing mechanism
because it's so ad hoc, so we're fixing it

573
00:48:09,859 --> 00:48:15,390
by having suspicions instead of detection,
and then we have false suspicions with alive

574
00:48:15,390 --> 00:48:20,291
messages, we have confirmations of non-false
suspicions with confirmation messages, all

575
00:48:20,291 --> 00:48:23,690
of these gossips are occurring in parallel.

576
00:48:23,690 --> 00:48:32,299
When there's a single very clear failure crash,
yes it will be detected, yes it will be spread

577
00:48:32,299 --> 00:48:34,309
in the network quite efficiently.

578
00:48:34,309 --> 00:48:39,990
You know, it will take a while, but eventually
with some gap everything will converge.

579
00:48:39,990 --> 00:48:45,099
When there are multiple occurrences in the
network, not clear.

580
00:48:45,099 --> 00:48:50,880
So some of the additional enhancements that
were needed in SWIM, because of these behaviors

581
00:48:50,880 --> 00:49:00,839
were, OK, so we don't really trust this randomized
probing to actually reach all nodes, you know,

582
00:49:00,839 --> 00:49:05,770
in time, so they've actually switched to deterministic
probing, so they go around round robbing and

583
00:49:05,770 --> 00:49:13,930
each has a round robinning regime to make
sure that no node is missed and the gossip

584
00:49:13,930 --> 00:49:19,079
itself piggybacks on the probing in order
to not create too many connections.

585
00:49:19,079 --> 00:49:25,020
So actually the gossip itself is not randomized.

586
00:49:25,020 --> 00:49:29,970
At the end of all of this, very importantly
what you get is a failure detection.

587
00:49:29,970 --> 00:49:32,430
In the paper it's called weak membership service.

588
00:49:32,430 --> 00:49:37,820
If you look at this it's a tiny little footnote
on the second page, footnote No. 2, that says

589
00:49:37,820 --> 00:49:43,430
that everything from now on has the adjective
weak added to it but we're not going to do

590
00:49:43,430 --> 00:49:44,430
it in this paper.

591
00:49:44,430 --> 00:49:50,119
So this is what you get at the end of all
of these patches.

592
00:49:50,119 --> 00:49:54,799
I'm going to stop here, because I don't want
to turn this into a papers we hate conference.

593
00:49:54,799 --> 00:49:58,590
[laughter]
I also hear that you know, some people are

594
00:49:58,590 --> 00:50:04,579
actually enhancing SWIM and trying to address
some of these difficulties that they're actually

595
00:50:04,579 --> 00:50:12,200
experiencing in real deployed systems, so
this is what it is.

596
00:50:12,200 --> 00:50:15,329
So I think I'm out of time.

597
00:50:15,329 --> 00:50:16,609
Where is Zeeshan?

598
00:50:16,609 --> 00:50:17,820
Should I stop for questions?

599
00:50:17,820 --> 00:50:19,650
Five minutes for questions, yeah.

600
00:50:19,650 --> 00:50:26,280
>> OK, I have a third part, but you're going
to have to invite me again to hear about it.

601
00:50:26,280 --> 00:50:27,280
That's fine.

602
00:50:27,280 --> 00:50:28,280
That's fine.

603
00:50:28,280 --> 00:50:29,280
Network discovery, great.

604
00:50:29,280 --> 00:50:30,810
ZEESHAN: We'll give you about 10 minutes.

605
00:50:30,810 --> 00:50:38,619
>> You know what I'm going to flash something
about network discovery and leave you to it.

606
00:50:38,619 --> 00:50:42,630
So one thing to realize is that all of this
was in a full network.

607
00:50:42,630 --> 00:50:44,690
What happens in, you know, arbitrary graphs?

608
00:50:44,690 --> 00:50:48,369
Well, clearly in some graphs this process
is going to take a long time.

609
00:50:48,369 --> 00:50:52,280
So if the graph is aligned, it's going to
take linear number of steps for a message

610
00:50:52,280 --> 00:50:54,340
to get from one side to another.

611
00:50:54,340 --> 00:51:01,430
There may even be graphs where it will be
super-linear, so this single barbell graph

612
00:51:01,430 --> 00:51:07,650
is a classic example where there's one node
connected to a dense clique and it may take

613
00:51:07,650 --> 00:51:15,030
a number of rounds until this one node is
picked by its single neighbor.

614
00:51:15,030 --> 00:51:20,880
So the question is what can you do in arbitrary
networks in general to disseminate information

615
00:51:20,880 --> 00:51:24,690
more quickly and I just want to flash a result.

616
00:51:24,690 --> 00:51:33,799
So there's a really -- a really beautiful
paper by the engineers at Akamai from 1999

617
00:51:33,799 --> 00:51:36,869
where they introduced the name-dropper algorithm.

618
00:51:36,869 --> 00:51:42,109
Allegedly it was used in some versions of
Akamai, I don't think it is any more.

619
00:51:42,109 --> 00:51:55,069
But very, very quickly, just to say what it
gives you, lots of demonstrations, so what

620
00:51:55,069 --> 00:52:00,869
it gives you is for any draff, even nondirected
graph.

621
00:52:00,869 --> 00:52:15,700
So if you think about the TCP/IP it doesn't
mean that that other node means my IP address,

622
00:52:15,700 --> 00:52:24,720
so even if the graph is only connect in a
directed way and not completely connected,

623
00:52:24,720 --> 00:52:29,160
the name dropper algorithm will collapse the
entire graph into a clique where everybody

624
00:52:29,160 --> 00:52:35,589
knows everybody in essentially log squared
n rounds.

625
00:52:35,589 --> 00:52:40,220
Even less, it's log n times log the diameter
of the graph, which is of course at most n,

626
00:52:40,220 --> 00:52:44,529
and that result has already been improved
somewhat with a deterministic protocol that

627
00:52:44,529 --> 00:52:51,430
actually brings it down to log n, so really
beautiful and powerful result tells that you

628
00:52:51,430 --> 00:52:56,010
even if your network is not a clique, you
can't talk to everybody at the same time,

629
00:52:56,010 --> 00:53:00,000
you can very quickly build the network through
this gossip protocol.

630
00:53:00,000 --> 00:53:06,900
Again, in essentially logarithmic process,
and within this logarithmic time everybody

631
00:53:06,900 --> 00:53:08,240
will know everybody else.

632
00:53:08,240 --> 00:53:13,140
And so with this, I will actually conclude.

633
00:53:13,140 --> 00:53:18,160
And open for questions.

634
00:53:18,160 --> 00:53:32,420
[applause]
>> What are the properties of the network

635
00:53:32,420 --> 00:53:34,170
that make this applicable or not applicable?

636
00:53:34,170 --> 00:53:35,930
Are there cases where you wouldn't want to
use gossip?

637
00:53:35,930 --> 00:53:41,710
Is it like the latency of the links or the
topology, that kind of thing or the total

638
00:53:41,710 --> 00:53:43,339
number of nodes versus bandwidth?

639
00:53:43,339 --> 00:53:47,089
>> So that's a good question.

640
00:53:47,089 --> 00:53:51,940
Probably people here have more experience.

641
00:53:51,940 --> 00:53:57,589
From a theoretical point of view, all of this
assumed, you know, very basic uniformity.

642
00:53:57,589 --> 00:54:03,130
So if there's really huge skews between latencies,
between nodes, some of them are really close

643
00:54:03,130 --> 00:54:10,529
by, others are, you know, off in the cloud
or away, gossip doesn't seem like a good choice,

644
00:54:10,529 --> 00:54:15,220
or at least straight gossip doesn't seem like
a good choose, because you have to tune these

645
00:54:15,220 --> 00:54:21,569
rounds to the slowest link.

646
00:54:21,569 --> 00:54:28,279
So gossip is fundamentally, you know, this
very uniform process, full knowledge, perfect

647
00:54:28,279 --> 00:54:35,940
knowledge, perfect ability to pick a partner
and you know, to succeed in directing with

648
00:54:35,940 --> 00:54:36,940
it.

649
00:54:36,940 --> 00:54:45,359
I actually don't know of many, many cases
where gossip in practice gives you a very,

650
00:54:45,359 --> 00:54:46,529
very good solution.

651
00:54:46,529 --> 00:54:51,380
This is why I wanted to speak about SWIM today,
because this is one of the very few emerging

652
00:54:51,380 --> 00:55:00,870
cases where people use gossip semi-successfully,
but stim with a lot of problems.

653
00:55:00,870 --> 00:55:02,749
Hope that answers.

654
00:55:02,749 --> 00:55:06,500
>> I just have a quick question.

655
00:55:06,500 --> 00:55:12,790
At the very beginning, you mentioned that
everyone has to know a priori, all of the

656
00:55:12,790 --> 00:55:14,730
other nodes that are in the network.

657
00:55:14,730 --> 00:55:21,920
I was wondering maybe you covered this and
I just missed it, how to step back other nodes

658
00:55:21,920 --> 00:55:28,069
leaving and joining the network on the gossiping
or is this handled outside of the gossip itself

659
00:55:28,069 --> 00:55:33,630
or --
>> Yeah, so the question is, if I can rephrase

660
00:55:33,630 --> 00:55:39,339
it, how can you use gossip to maintain membership
when you need membership to make gossip operate?

661
00:55:39,339 --> 00:55:41,470
And I'm asking myself the same question.

662
00:55:41,470 --> 00:55:48,910
Yes, the only analysis that we have is when
you have full and perfect ability to sample

663
00:55:48,910 --> 00:55:49,910
the network.

664
00:55:49,910 --> 00:55:55,160
What happens if you have partial sample that's
not really uniform?

665
00:55:55,160 --> 00:55:57,319
We don't know.

666
00:55:57,319 --> 00:55:59,289
(Shrugs).

667
00:55:59,289 --> 00:56:03,990
[laughter]
>> With the SWIM protocol on large networks

668
00:56:03,990 --> 00:56:08,220
has it ever been a concern that when you're
trying to reconfirm a failure that you're

669
00:56:08,220 --> 00:56:12,990
actually going to do like some kind of denial
of service against that node and then have

670
00:56:12,990 --> 00:56:17,510
a certain ratio of failures that just kind
of never goes away?

671
00:56:17,510 --> 00:56:20,290
>> I haven't seen such a concern.

672
00:56:20,290 --> 00:56:29,260
I don't think security was at all a consideration
in any of these protocols.

673
00:56:29,260 --> 00:56:34,329
I'll take this opportunity to say a comment
that may or may not stem from what you're

674
00:56:34,329 --> 00:56:39,890
asking, so Byzantine failures or malicious
intrusions, these protocols are not built

675
00:56:39,890 --> 00:56:40,890
to tolerate.

676
00:56:40,890 --> 00:56:46,210
But let me also say fundamentally it seems
to me that when failures occur, there are

677
00:56:46,210 --> 00:56:49,430
essentially two classes of scenarios.

678
00:56:49,430 --> 00:56:57,070
One is when there's single failure or, you
know, very few nodes fail, and fail in kind

679
00:56:57,070 --> 00:56:59,880
of a black or white way.

680
00:56:59,880 --> 00:57:01,720
They crash and that's it.

681
00:57:01,720 --> 00:57:08,369
The other is when there's some transient partition,
half the network is partitioned away from

682
00:57:08,369 --> 00:57:13,089
you maybe permanently, maybe it is black and
white or there is some transient fail ore

683
00:57:13,089 --> 00:57:20,740
where messages are dropped excessively but
not completely, the first type, I think almost

684
00:57:20,740 --> 00:57:25,779
any mechanism that you implement will work
with, you could do just a group of monitors,

685
00:57:25,779 --> 00:57:31,990
you could do all to all, you could do almost
anything and probably also SWIM will converge

686
00:57:31,990 --> 00:57:34,039
very quickly in that setting.

687
00:57:34,039 --> 00:57:39,559
The second type of scenario, that's where
you know, the mechanism really is put to a

688
00:57:39,559 --> 00:57:44,940
test and it's not exactly Byzantine so it's
not exactly what you're asking, but it will

689
00:57:44,940 --> 00:57:52,410
cause removal of nonfaulty nodes and errors
and false failure detections and all of that.

690
00:57:52,410 --> 00:57:59,750
So I think that the effort in tuning a system
and engineering it correctly should be on

691
00:57:59,750 --> 00:58:04,150
the second case and that's what should be
test and optimized for.

692
00:58:04,150 --> 00:58:05,869
Does that address at all?

693
00:58:05,869 --> 00:58:09,029
Yeah, I don't seem to have a good luck with
you --

694
00:58:09,029 --> 00:58:12,539
[laughter]
>> I mean the strict answer is, no, I haven't

695
00:58:12,539 --> 00:58:13,539
seen any.

696
00:58:13,539 --> 00:58:16,450
>> I wasn't really getting into the security
part.

697
00:58:16,450 --> 00:58:18,480
Just the protocol itself.

698
00:58:18,480 --> 00:58:21,529
Where they're being reflooded with reconfirmations.

699
00:58:21,529 --> 00:58:29,970
>> Yeah, so I mean this confirmations in a
nonsteady state could cause removal of a perfectly

700
00:58:29,970 --> 00:58:30,970
OK node, yes.

701
00:58:30,970 --> 00:58:40,910
>> Certain percentage saying, OK, it is alive,
and a certain percentage saying it's OK, and

702
00:58:40,910 --> 00:58:47,030
constantly -- maybe we should talk about this
later.

703
00:58:47,030 --> 00:58:48,030
>> Sure.

704
00:58:48,030 --> 00:58:49,030
>> Last question.

705
00:58:49,030 --> 00:58:50,960
>> I noticed in the example that it was primarily
binary, healthy, not healthy.

706
00:58:50,960 --> 00:58:55,240
Is there the option of accommodating something
more like a nice factor where it's like I've

707
00:58:55,240 --> 00:59:03,099
had trouble against that particular node 30%
of the time because in a degrading state,

708
00:59:03,099 --> 00:59:08,000
something will often go from full up time
to 50% to 15%, so I'm just wondering if the

709
00:59:08,000 --> 00:59:11,990
gossip protocol could accommodate matching
that range.

710
00:59:11,990 --> 00:59:14,420
>> I think gossip spreads that information.

711
00:59:14,420 --> 00:59:17,990
What you do with it, I think yes.

712
00:59:17,990 --> 00:59:20,090
Or how you interpret it.

713
00:59:20,090 --> 00:59:21,050
Whichever way you want.

714
00:59:22,079 --> 00:59:23,079
Right, thank you very much.

715
00:59:23,079 --> 00:59:24,079
Been a great audience.

716
00:59:24,079 --> 00:59:24,579
[applause]

